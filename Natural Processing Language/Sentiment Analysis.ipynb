{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPbeQhuq62gmIIDoSmT81VT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Load data\n","\n","Leyendo el csv"],"metadata":{"id":"3zQYS3OI2iMN"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"UfkhjQh40e0-","executionInfo":{"status":"ok","timestamp":1688174858903,"user_tz":360,"elapsed":684,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}}},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","source":["df = pd.read_csv(\"/content/flipkart_review_data_2022_02.csv\")\n","df = df.drop(columns=\"Unnamed: 0\")"],"metadata":{"id":"cOYRX9fh1LKy","executionInfo":{"status":"ok","timestamp":1688174858904,"user_tz":360,"elapsed":3,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Total de elementos\n","df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VRJ1N9pN3-Ee","executionInfo":{"status":"ok","timestamp":1688174859906,"user_tz":360,"elapsed":3,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}},"outputId":"a7db460e-3636-4cb7-d001-8ec10ee0ae0c"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(343, 14)"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["df.head(3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"8diEhsGr1fvD","executionInfo":{"status":"ok","timestamp":1688174860566,"user_tz":360,"elapsed":4,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}},"outputId":"99da6a99-dc2d-4eea-a85d-21f0dbe73054"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                          ProductUrl  \\\n","0  https://www.flipkart.com/lg-108-cm-43-inch-ult...   \n","1  https://www.flipkart.com/lg-108-cm-43-inch-ult...   \n","2  https://www.flipkart.com/lg-108-cm-43-inch-ult...   \n","\n","                                     productTitle productPrice  averageRating  \\\n","0  LG 108 cm (43 inch) Ultra HD (4K) LED Smart TV      ₹36,499            4.4   \n","1  LG 108 cm (43 inch) Ultra HD (4K) LED Smart TV      ₹36,499            4.4   \n","2  LG 108 cm (43 inch) Ultra HD (4K) LED Smart TV      ₹36,499            4.4   \n","\n","   reviewTitle                                  reviewDescription  \\\n","0    Excellent                                  Very good product   \n","1  Really Nice  Nice and super picture quality.and sound also ...   \n","2       Super!  This is excellent picture qualityUltimate soun...   \n","\n","             reviewAuthor      reviewAt  reviewLikes  reviewDislikes  \\\n","0       palakollu  komali  6 months ago            0               1   \n","1          Yogesh  Virkar  3 months ago            0               0   \n","2  Sudhir Kumar Chaudhary  3 months ago            0               0   \n","\n","   certifiedBuyer reviewerLocation            scrapedAt  \\\n","0            True           Tenali  20/02/2022 02:03:42   \n","1            True           Mumbai  20/02/2022 02:03:42   \n","2            True         Haridwar  20/02/2022 02:03:42   \n","\n","                                 uniqId  \n","0  4e9df8d3-736c-5dae-b867-b92b7f09fc84  \n","1  7ba04258-9f05-5642-ba33-8982db1f6c5e  \n","2  bfb20e97-eacf-5b76-a5eb-91999d6bd7a3  "],"text/html":["\n","  <div id=\"df-503681d3-f03b-4708-b20e-bf4f0d172a24\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ProductUrl</th>\n","      <th>productTitle</th>\n","      <th>productPrice</th>\n","      <th>averageRating</th>\n","      <th>reviewTitle</th>\n","      <th>reviewDescription</th>\n","      <th>reviewAuthor</th>\n","      <th>reviewAt</th>\n","      <th>reviewLikes</th>\n","      <th>reviewDislikes</th>\n","      <th>certifiedBuyer</th>\n","      <th>reviewerLocation</th>\n","      <th>scrapedAt</th>\n","      <th>uniqId</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>https://www.flipkart.com/lg-108-cm-43-inch-ult...</td>\n","      <td>LG 108 cm (43 inch) Ultra HD (4K) LED Smart TV</td>\n","      <td>₹36,499</td>\n","      <td>4.4</td>\n","      <td>Excellent</td>\n","      <td>Very good product</td>\n","      <td>palakollu  komali</td>\n","      <td>6 months ago</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>Tenali</td>\n","      <td>20/02/2022 02:03:42</td>\n","      <td>4e9df8d3-736c-5dae-b867-b92b7f09fc84</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>https://www.flipkart.com/lg-108-cm-43-inch-ult...</td>\n","      <td>LG 108 cm (43 inch) Ultra HD (4K) LED Smart TV</td>\n","      <td>₹36,499</td>\n","      <td>4.4</td>\n","      <td>Really Nice</td>\n","      <td>Nice and super picture quality.and sound also ...</td>\n","      <td>Yogesh  Virkar</td>\n","      <td>3 months ago</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>True</td>\n","      <td>Mumbai</td>\n","      <td>20/02/2022 02:03:42</td>\n","      <td>7ba04258-9f05-5642-ba33-8982db1f6c5e</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>https://www.flipkart.com/lg-108-cm-43-inch-ult...</td>\n","      <td>LG 108 cm (43 inch) Ultra HD (4K) LED Smart TV</td>\n","      <td>₹36,499</td>\n","      <td>4.4</td>\n","      <td>Super!</td>\n","      <td>This is excellent picture qualityUltimate soun...</td>\n","      <td>Sudhir Kumar Chaudhary</td>\n","      <td>3 months ago</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>True</td>\n","      <td>Haridwar</td>\n","      <td>20/02/2022 02:03:42</td>\n","      <td>bfb20e97-eacf-5b76-a5eb-91999d6bd7a3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-503681d3-f03b-4708-b20e-bf4f0d172a24')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-503681d3-f03b-4708-b20e-bf4f0d172a24 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-503681d3-f03b-4708-b20e-bf4f0d172a24');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["A primera vista, la variable objetivo podría ser la columna \"averageRating\" o \"reviewTitle\""],"metadata":{"id":"WPOaeO4N23CT"}},{"cell_type":"code","source":["# Conteo inicial de la variable 'target'\n","df.groupby(\"averageRating\")[\"averageRating\"].count()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CUF2MVez2nBq","executionInfo":{"status":"ok","timestamp":1688174862324,"user_tz":360,"elapsed":192,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}},"outputId":"4acfee93-72ba-4adc-cd9a-34927ebd9c56"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["averageRating\n","4.4    343\n","Name: averageRating, dtype: int64"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["# Revisando los datos, es necesario organizarlo en positive/negative\n","# y disminuir la cardinalidad de la tabla\n","df.groupby(\"reviewTitle\")[\"reviewTitle\"].count().sort_values(ascending=False).head(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pfSeRlQ93oaR","executionInfo":{"status":"ok","timestamp":1688174863073,"user_tz":360,"elapsed":4,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}},"outputId":"9b99e140-5f34-46de-da75-9af020cebb04"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["reviewTitle\n","Classy product         22\n","Great product          20\n","Wonderful              17\n","Perfect product!       15\n","Best in the market!    14\n","Highly recommended     14\n","Must buy!              13\n","Excellent              13\n","Worth the money        13\n","Worth every penny      12\n","Name: reviewTitle, dtype: int64"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["# Podríamos filtrar los comentarios por likes\n","# dejando los más relevantes, o eliminado aquellos\n","# con mayor dislikes\n","df.describe()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"id":"rmTtdxa938jR","executionInfo":{"status":"ok","timestamp":1688174863621,"user_tz":360,"elapsed":233,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}},"outputId":"a8352f36-a39b-4829-fdfe-9aaea8733bb0"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       averageRating  reviewLikes  reviewDislikes\n","count   3.430000e+02   343.000000      343.000000\n","mean    4.400000e+00     4.309038        1.755102\n","std     1.778952e-15    15.885670        6.466610\n","min     4.400000e+00     0.000000        0.000000\n","25%     4.400000e+00     0.000000        0.000000\n","50%     4.400000e+00     0.000000        0.000000\n","75%     4.400000e+00     3.000000        1.000000\n","max     4.400000e+00   235.000000       64.000000"],"text/html":["\n","  <div id=\"df-5637b371-b314-48bb-a534-968f79b5050b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>averageRating</th>\n","      <th>reviewLikes</th>\n","      <th>reviewDislikes</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>3.430000e+02</td>\n","      <td>343.000000</td>\n","      <td>343.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>4.400000e+00</td>\n","      <td>4.309038</td>\n","      <td>1.755102</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>1.778952e-15</td>\n","      <td>15.885670</td>\n","      <td>6.466610</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>4.400000e+00</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>4.400000e+00</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>4.400000e+00</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>4.400000e+00</td>\n","      <td>3.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>4.400000e+00</td>\n","      <td>235.000000</td>\n","      <td>64.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5637b371-b314-48bb-a534-968f79b5050b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5637b371-b314-48bb-a534-968f79b5050b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5637b371-b314-48bb-a534-968f79b5050b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["# Eliminaré el 5% de comentarios con más dislikes\n","q_05_dislikes = df[\"reviewDislikes\"].quantile(0.99)\n","q_05_dislikes"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HOx-AxJ-36Ls","executionInfo":{"status":"ok","timestamp":1688174864591,"user_tz":360,"elapsed":185,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}},"outputId":"6fca43a0-6a7d-45eb-bba4-6728ed42a44a"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["35.0"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["df = df[df.reviewDislikes < q_05_dislikes]"],"metadata":{"id":"XSnYgEzO6Zw5","executionInfo":{"status":"ok","timestamp":1688174865238,"user_tz":360,"elapsed":1,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Después del filtrado nos quedamos con 325 comentarios\n","df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_fJlhbqY7BM8","executionInfo":{"status":"ok","timestamp":1688174866052,"user_tz":360,"elapsed":3,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}},"outputId":"bb89e959-3910-40de-bdf3-a9568bb786c3"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(338, 14)"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# Creando dos etiquetas: Bueno y Malo\n","\n","# [1] Obteniendo valores únicos\n","\n","unique_titles = df[\"reviewTitle\"].unique()\n","unique_titles"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HjTSuMSI7NM5","executionInfo":{"status":"ok","timestamp":1688174866558,"user_tz":360,"elapsed":2,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}},"outputId":"d6e09b22-9481-46aa-80f0-ec9b87f0f715"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['Excellent', 'Really Nice', 'Super!', 'Just wow!',\n","       'Highly recommended', 'Great product', 'Worth the money',\n","       'Good quality product', 'Nice', 'Decent product',\n","       'Perfect product!', 'Classy product', 'Terrific', 'Good choice',\n","       'Fabulous!', 'Worth every penny', 'Wonderful', 'Simply awesome',\n","       'Very Good', 'Terrific purchase', 'Brilliant',\n","       'Mind-blowing purchase', 'Must buy!', 'Pretty good', 'Awesome',\n","       'Best in the market!', 'Value-for-money', 'Fair', 'Hated it!',\n","       'Just okay', 'Could be way better', 'Useless product',\n","       'Unsatisfactory', 'Not good', 'Delightful', 'Good', 'Nice product',\n","       'Very poor', 'Moderate', 'Does the job', 'Utterly Disappointed',\n","       'Worst experience ever!', 'Expected a better product',\n","       'Not recommended at all', 'Waste of money!', 'Absolute rubbish!',\n","       'Did not meet expectations'], dtype=object)"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# Etiquetado manual de la información\n","new_categories_dict = {\n","    \"good\": ['Excellent', 'Really Nice', 'Super!', 'Just wow!',\n","       'Highly recommended', 'Great product', 'Worth the money',\n","       'Good quality product', 'Nice', 'Decent product',\n","       'Perfect product!', 'Classy product', 'Terrific', 'Good choice',\n","       'Fabulous!', 'Worth every penny', 'Wonderful', 'Simply awesome',\n","       'Very Good', 'Terrific purchase', 'Brilliant',\n","       'Mind-blowing purchase', 'Must buy!', 'Pretty good', 'Awesome',\n","       'Best in the market!', 'Value-for-money', 'Fair', 'Nice product',\n","       'Delightful', 'Good', 'Does the job'],\n","\n","    \"bad\": ['Slightly disappointed', 'Hated it!', 'Just okay',\n","            'Could be way better', 'Useless product', 'Unsatisfactory',\n","            'Very poor', 'Moderate', 'Not good',\n","            'Utterly Disappointed', 'Worst experience ever!',\n","            'Expected a better product', 'Not recommended at all',\n","            'Waste of money!', 'Absolute rubbish!',\n","            'Did not meet expectations', \"Hated it!\",\n","            \"Not good\", \"Useless product\"]\n","}\n","\n","def relabel_target(title: pd.Series):\n","  \"\"\"Returns a new category according to the new labes dictionary\"\"\"\n","  new_category = \"not found\"\n","\n","  for category in new_categories_dict.keys():\n","    if title in new_categories_dict[category]:\n","      new_category = category\n","      break\n","\n","  return new_category"],"metadata":{"id":"rOyk7KYn7g04","executionInfo":{"status":"ok","timestamp":1688174867489,"user_tz":360,"elapsed":1,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["df[\"sentiment\"] = df[\"reviewTitle\"].apply(relabel_target)"],"metadata":{"id":"0wPaRYME-BHH","executionInfo":{"status":"ok","timestamp":1688174868089,"user_tz":360,"elapsed":2,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Nueva distribución de categorias\n","# Lo primero que podemos observar es que se encuentra\n","# Imbalanceado\n","df.groupby(\"sentiment\")[\"sentiment\"].count()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P0Ifn7Us-TPU","executionInfo":{"status":"ok","timestamp":1688174868341,"user_tz":360,"elapsed":2,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}},"outputId":"761d59df-511b-4a1c-de78-558ad6608d5c"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["sentiment\n","bad      20\n","good    318\n","Name: sentiment, dtype: int64"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["# Train, Test"],"metadata":{"id":"h-hs5zqNw8JF"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","# Normalmente se usa un 80-20 o 70-30 para\n","# para el modelo, pero ya que son muy pocos datos,\n","# se utilizará un muestra pequena para testear los datos\n","train, test = train_test_split(df, test_size=0.2,\n","                               random_state=0, stratify=df[\"sentiment\"])"],"metadata":{"id":"RyD8yz5MosGe","executionInfo":{"status":"ok","timestamp":1688174871215,"user_tz":360,"elapsed":1430,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["train.groupby(\"sentiment\")[\"sentiment\"].count()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xER8legrJIWE","executionInfo":{"status":"ok","timestamp":1688174871909,"user_tz":360,"elapsed":3,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}},"outputId":"a10826e9-ad8d-4c48-9113-5778b5ce2b40"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["sentiment\n","bad      16\n","good    254\n","Name: sentiment, dtype: int64"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["round(train.groupby(\"sentiment\")[\"sentiment\"].count() / train.shape[0] * 100, 2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3egALQJsHk7K","executionInfo":{"status":"ok","timestamp":1688174873648,"user_tz":360,"elapsed":230,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}},"outputId":"80bea4be-e9cd-4a12-c60d-6ef38d734429"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["sentiment\n","bad      5.93\n","good    94.07\n","Name: sentiment, dtype: float64"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["test.groupby(\"sentiment\")[\"sentiment\"].count()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lGkrvLKHJL8c","executionInfo":{"status":"ok","timestamp":1688174875701,"user_tz":360,"elapsed":134,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}},"outputId":"b396d932-eae3-491a-f5dd-35dc332ec588"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["sentiment\n","bad      4\n","good    64\n","Name: sentiment, dtype: int64"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["round(test.groupby(\"sentiment\")[\"sentiment\"].count() / test.shape[0] * 100, 2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9hqit8Cpy4aN","executionInfo":{"status":"ok","timestamp":1688174877491,"user_tz":360,"elapsed":162,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}},"outputId":"1d7ec3db-eb8e-4f9e-a7e8-d5019855faab"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["sentiment\n","bad      5.88\n","good    94.12\n","Name: sentiment, dtype: float64"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["Para tratar datos no balanceados, podemos:\n","- Realizar un sub-muestreo de la data que tiene mayor cantidad de datos\n","- Realizar un sobre-muestreo de la etiqueta con menor cantidad de datos\n","- Usar K-fold cross validation\n","- Ensamblado de diferentes modelos, realizando un submuestreo de la categoría con mayor cantidad de datos\n","y siempre usando la categoría con menos datos\n","\n","Por el tiempo disponible optare por K-fold cross validation que se integra dentro GridSearch."],"metadata":{"id":"1Qo-9EV9A1io"}},{"cell_type":"markdown","source":["# Preprocess (data cleaning)\n","\n","La columna reviewDescription será utilizada como feature para la construcción del modelo, el preprocesamiento incluye:\n","\n","- Eliminar signos de puntuación\n","- Convertir a minúsculas\n","- Remover palabras más comunes (stopwords)\n","- Lematización: llevar a la raiz\n","- Remover palabras menores a 2 letras\n","- Vectorizar la información\n"],"metadata":{"id":"kUthLX1wCz-w"}},{"cell_type":"code","source":["import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer"],"metadata":{"id":"xltZW5mGD1st","executionInfo":{"status":"ok","timestamp":1688174880352,"user_tz":360,"elapsed":399,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# Descargando librería stopwords\n","nltk.download('stopwords')\n","# Descargando librería para lematización\n","nltk.download('wordnet')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a3VOiQrPD7Bj","executionInfo":{"status":"ok","timestamp":1688174880950,"user_tz":360,"elapsed":3,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}},"outputId":"ccd02f7d-82e4-49e1-ac4b-ecdf7c8dd483"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["# Obteniendo stopwords para idioma inglés\n","STOPWORDS = nltk.corpus.stopwords.words('english')"],"metadata":{"id":"cBkW19xTHkeI","executionInfo":{"status":"ok","timestamp":1688174881689,"user_tz":360,"elapsed":2,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["# Instalando librería para eliminar emojis\n","!pip install emoji"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"15JqnYzdTchu","executionInfo":{"status":"ok","timestamp":1688174888132,"user_tz":360,"elapsed":5821,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}},"outputId":"fb979c0b-ffdd-4382-8377-53f854db28cd"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (2.6.0)\n"]}]},{"cell_type":"code","source":["import emoji"],"metadata":{"id":"BNXfQ5TDiWWk","executionInfo":{"status":"ok","timestamp":1688174888133,"user_tz":360,"elapsed":6,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["LEMMATIZER = WordNetLemmatizer()\n","\n","def remove_stopwords(text: str) -> str:\n","  text_processed = \" \".join(word for word in text.split(\" \") if word not in STOPWORDS)\n","  return text_processed\n","\n","\n","def remove_punctuation(text: str) -> str:\n","  remove_chars_list = [\"?\", \",\", \".\", \";\", \":\",  \"!\",'\"']\n","\n","  for char in remove_chars_list:\n","    text = text.replace(char, \" \")\n","\n","  return text\n","\n","\n","def lemmatisation(text: str) -> str:\n","  return \" \".join(LEMMATIZER.lemmatize(word) for word in text.split(\" \"))\n","\n","\n","def remove_emoji(text: str) -> str:\n","  return emoji.replace_emoji(text, '')\n","\n","\n","def remove_short_words(text: str) -> str:\n","  return \" \".join(word for word in text.split(\" \") if len(word) > 2)\n","\n","\n","def encode_categories(df: pd.DataFrame) -> pd.DataFrame:\n","  df.loc[df[\"sentiment\"] == \"good\", \"target\"] = 1\n","  df.loc[df[\"sentiment\"] == \"bad\", \"target\"] = 0\n","\n","  return df"],"metadata":{"id":"oe7DKwWVFhLh","executionInfo":{"status":"ok","timestamp":1688174888133,"user_tz":360,"elapsed":5,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["def process_text(df: pd.DataFrame) -> pd.DataFrame:\n","  # [0] Combinando titulo y la descripción\n","  df[\"feature\"] = df[\"reviewTitle\"]  + \" \" + df[\"reviewDescription\"]\n","  # [1] Eliminando signos de puntuación\n","  df[\"feature\"] = df['feature'].apply(remove_punctuation)\n","  # [2] Convirtiendo a minúscula\n","  df[\"feature\"] = df['feature'].str.lower()\n","  # [3] Eliminando las palabras más comunes\n","  df[\"feature\"] = df['feature'].apply(remove_stopwords)\n","  # [4] Lematización\n","  df[\"feature\"] = df['feature'].apply(lemmatisation)\n","  # [5] Removiendo emojis\n","  df[\"feature\"] = df['feature'].apply(remove_emoji)\n","  # [6] Filtrando palabras muy cortas\n","  df[\"feature\"] = df['feature'].apply(remove_short_words)\n","  # [7] Eliminando espacios en blanco al inicio y final del texto\n","  df[\"feature\"] = df['feature'].str.strip()\n","\n","  return df"],"metadata":{"id":"CRYjyHhhnuDd","executionInfo":{"status":"ok","timestamp":1688174888133,"user_tz":360,"elapsed":5,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["# Aplicando el procesamiento a datos de entrenamiento\n","train_processed = process_text(train)\n","train_processed = encode_categories(train_processed)"],"metadata":{"id":"w5nTPGSsn8tc","executionInfo":{"status":"ok","timestamp":1688174890918,"user_tz":360,"elapsed":2790,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["# Revisión de la limpieza del texto\n","train_processed[[\"reviewTitle\", \"reviewDescription\", \"feature\", \"target\"]].sample(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":302},"id":"uPEJOuc3GVB1","executionInfo":{"status":"ok","timestamp":1688174890918,"user_tz":360,"elapsed":6,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}},"outputId":"0e88b58e-f6e8-40b3-905d-135c740e24ec"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["           reviewTitle                                  reviewDescription  \\\n","220  Terrific purchase  Super TV #Lg , thanks lg,  thank u flipkart Do...   \n","209          Fabulous!                                               Good   \n","125      Great product  Very Nice Video Quality. Good Sound. Good User...   \n","149    Value-for-money                             Good deal on flipkart.   \n","44           Brilliant                      Product and service excellent   \n","\n","                                               feature  target  \n","220  terrific purchase super #lg thanks thank flipk...     1.0  \n","209                                      fabulous good     1.0  \n","125  great product nice video quality good sound go...     1.0  \n","149                 value-for-money good deal flipkart     1.0  \n","44                 brilliant product service excellent     1.0  "],"text/html":["\n","  <div id=\"df-7d79749b-efc6-43f8-a8f6-d308693342e3\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>reviewTitle</th>\n","      <th>reviewDescription</th>\n","      <th>feature</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>220</th>\n","      <td>Terrific purchase</td>\n","      <td>Super TV #Lg , thanks lg,  thank u flipkart Do...</td>\n","      <td>terrific purchase super #lg thanks thank flipk...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>209</th>\n","      <td>Fabulous!</td>\n","      <td>Good</td>\n","      <td>fabulous good</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>125</th>\n","      <td>Great product</td>\n","      <td>Very Nice Video Quality. Good Sound. Good User...</td>\n","      <td>great product nice video quality good sound go...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>149</th>\n","      <td>Value-for-money</td>\n","      <td>Good deal on flipkart.</td>\n","      <td>value-for-money good deal flipkart</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>Brilliant</td>\n","      <td>Product and service excellent</td>\n","      <td>brilliant product service excellent</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d79749b-efc6-43f8-a8f6-d308693342e3')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7d79749b-efc6-43f8-a8f6-d308693342e3 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7d79749b-efc6-43f8-a8f6-d308693342e3');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":28}]},{"cell_type":"markdown","source":["# Information Processing (vectorization)\n","\n","A continuación procedere a vectorizar el texto para que pueda alimentar al modelo."],"metadata":{"id":"sLmpt6bzqiFF"}},{"cell_type":"code","source":["# Term Frequency Inverse Document Frequency\n","# Considera el peso de las palabras y es una opción\n","# popular para la vectorización del text\n","from sklearn.feature_extraction.text import TfidfVectorizer"],"metadata":{"id":"5fah0dpZqsgd","executionInfo":{"status":"ok","timestamp":1688174890918,"user_tz":360,"elapsed":4,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["vectorizer = TfidfVectorizer()\n","train_vec = vectorizer.fit_transform(train_processed[\"feature\"])"],"metadata":{"id":"H_P9HeaYY7-M","executionInfo":{"status":"ok","timestamp":1688174890918,"user_tz":360,"elapsed":4,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["df_x_train = pd.DataFrame.sparse.from_spmatrix(train_vec)\n","df_x_train.sample(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":299},"id":"fh7Fy2SGNNIl","executionInfo":{"status":"ok","timestamp":1688174891437,"user_tz":360,"elapsed":171,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}},"outputId":"62d8e230-2a82-440b-a6f8-55d81deb1f5c"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     0    1    2         3    4    5    6    7    8    9    ...  799  800  \\\n","244  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n","231  0.0  0.0  0.0  0.146953  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n","191  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n","50   0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n","243  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n","\n","     801  802  803  804  805  806  807       808  \n","244  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  \n","231  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.129715  \n","191  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  \n","50   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  \n","243  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  \n","\n","[5 rows x 809 columns]"],"text/html":["\n","  <div id=\"df-7f5fe6c5-a374-4fdb-921a-05d4687c75f4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>799</th>\n","      <th>800</th>\n","      <th>801</th>\n","      <th>802</th>\n","      <th>803</th>\n","      <th>804</th>\n","      <th>805</th>\n","      <th>806</th>\n","      <th>807</th>\n","      <th>808</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>244</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>231</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.146953</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.129715</td>\n","    </tr>\n","    <tr>\n","      <th>191</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>243</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 809 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f5fe6c5-a374-4fdb-921a-05d4687c75f4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7f5fe6c5-a374-4fdb-921a-05d4687c75f4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7f5fe6c5-a374-4fdb-921a-05d4687c75f4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["# Guardar el vectorizar en un archivo pickle\n","import pickle"],"metadata":{"id":"phgtitlE2s0j","executionInfo":{"status":"ok","timestamp":1688174892664,"user_tz":360,"elapsed":2,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["VECTORIZER_PATH = '/content/vectorizer'\n","file = open(VECTORIZER_PATH, 'wb')\n","pickle.dump(vectorizer, file)\n","file.close()"],"metadata":{"id":"ekOSWNKT3Uri","executionInfo":{"status":"ok","timestamp":1688174893492,"user_tz":360,"elapsed":2,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["from typing import Any\n","\n","def save_to_pickle(obj: Any, path: str) -> None:\n","  file = open(path, 'wb')\n","  pickle.dump(obj, file)\n","  file.close()"],"metadata":{"id":"fowdEt6k7Ria","executionInfo":{"status":"ok","timestamp":1688174894617,"user_tz":360,"elapsed":406,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["def vectorize_features(df: pd.DataFrame, ) -> pd.DataFrame:\n","  file = open(VECTORIZER_PATH, 'rb')\n","  vectorizer = pickle.load(file)\n","  file.close()\n","\n","  train_vec = vectorizer.transform(df)\n","  df_vectorized = pd.DataFrame.sparse.from_spmatrix(train_vec)\n","\n","  return df_vectorized"],"metadata":{"id":"AYgL1XdU2XMI","executionInfo":{"status":"ok","timestamp":1688174895089,"user_tz":360,"elapsed":2,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["# Resumen del vocabulario aprendido\n","# data_vec = {k: [v] for k, v in vectorizer.vocabulary_.items()}\n","# pd.DataFrame.from_dict(data_vec, orient=\"index\").sort_values(0, ascending=False).head(10)"],"metadata":{"id":"tW0CZCrfYPj_","executionInfo":{"status":"ok","timestamp":1688174896508,"user_tz":360,"elapsed":425,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["# [1] Preprocseamiento (limpieza del texto)\n","test_processed = process_text(test)\n","# [2] Vectorización\n","df_x_test = vectorize_features(test_processed[\"feature\"])"],"metadata":{"id":"hKS0n-Lr1-O2","executionInfo":{"status":"ok","timestamp":1688174897442,"user_tz":360,"elapsed":192,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["df_x_test.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":299},"id":"cPi4ddDQ41OW","executionInfo":{"status":"ok","timestamp":1688174898744,"user_tz":360,"elapsed":435,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}},"outputId":"bd395933-5903-40a9-d993-db651c340c42"},"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   0    1    2    3    4    5    6    7    8    9    ...  799  800  801  802  \\\n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n","3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n","4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n","\n","   803  804       805  806  807  808  \n","0  0.0  0.0  0.258217  0.0  0.0  0.0  \n","1  0.0  0.0  0.000000  0.0  0.0  0.0  \n","2  0.0  0.0  0.000000  0.0  0.0  0.0  \n","3  0.0  0.0  0.000000  0.0  0.0  0.0  \n","4  0.0  0.0  0.000000  0.0  0.0  0.0  \n","\n","[5 rows x 809 columns]"],"text/html":["\n","  <div id=\"df-c30ce664-2ab6-4db8-8949-929c50941cb7\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>799</th>\n","      <th>800</th>\n","      <th>801</th>\n","      <th>802</th>\n","      <th>803</th>\n","      <th>804</th>\n","      <th>805</th>\n","      <th>806</th>\n","      <th>807</th>\n","      <th>808</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.258217</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 809 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c30ce664-2ab6-4db8-8949-929c50941cb7')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c30ce664-2ab6-4db8-8949-929c50941cb7 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c30ce664-2ab6-4db8-8949-929c50941cb7');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":38}]},{"cell_type":"markdown","source":["# Model training"],"metadata":{"id":"3dmllg-j1JVN"}},{"cell_type":"markdown","source":["## Logistic Regression\n"],"metadata":{"id":"IdznHq8vgNVR"}},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import GridSearchCV\n","import numpy as np"],"metadata":{"id":"yhxURvFjKtSB","executionInfo":{"status":"ok","timestamp":1688174901997,"user_tz":360,"elapsed":375,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["# Obteniendo y_train para el entrenamiento del modelo\n","y_train = train_processed[\"target\"]"],"metadata":{"id":"H8K64NLW0cpT","executionInfo":{"status":"ok","timestamp":1688174907037,"user_tz":360,"elapsed":133,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["parameters = {\n","    'penalty' : ['l1','l2'],\n","    'C'       : np.logspace(-3,3,7),\n","    'solver'  : ['newton-cg', 'lbfgs', 'liblinear'],\n","}\n","\n","logreg = LogisticRegression()\n","\n","# GridSearchCV\n","# Crea un modelo por cada combinación del conjunto de parametros\n","# definidos, y los evalúa usando cross validation.\n","# Genera y evalua un total de 210 modelos y al final elegimos el mejor\n","\n","logreg_gs = GridSearchCV(\n","    estimator=logreg,\n","    param_grid = parameters,\n","    # Una buen métrica para evaluar el modelo es f1-score,\n","    # ya que los datos se encuentran desbalaceados\n","    scoring='f1_macro',\n","    cv=5,\n","    n_jobs=-3,\n","    verbose=10,\n",")\n","\n","logreg_gs.fit(df_x_train, y_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"hYkIcWBDgQ5C","executionInfo":{"status":"ok","timestamp":1688175487088,"user_tz":360,"elapsed":70010,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}},"outputId":"988bd238-474d-4dfd-8cf0-d1b225ad9e2f"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 42 candidates, totalling 210 fits\n","[CV 1/5; 1/42] START C=0.001, penalty=l1, solver=newton-cg......................\n","[CV 1/5; 1/42] END C=0.001, penalty=l1, solver=newton-cg;, score=nan total time=   0.4s\n","[CV 2/5; 1/42] START C=0.001, penalty=l1, solver=newton-cg......................\n","[CV 2/5; 1/42] END C=0.001, penalty=l1, solver=newton-cg;, score=nan total time=   0.4s\n","[CV 3/5; 1/42] START C=0.001, penalty=l1, solver=newton-cg......................\n","[CV 3/5; 1/42] END C=0.001, penalty=l1, solver=newton-cg;, score=nan total time=   0.6s\n","[CV 4/5; 1/42] START C=0.001, penalty=l1, solver=newton-cg......................\n","[CV 4/5; 1/42] END C=0.001, penalty=l1, solver=newton-cg;, score=nan total time=   0.3s\n","[CV 5/5; 1/42] START C=0.001, penalty=l1, solver=newton-cg......................\n","[CV 5/5; 1/42] END C=0.001, penalty=l1, solver=newton-cg;, score=nan total time=   0.2s\n","[CV 1/5; 2/42] START C=0.001, penalty=l1, solver=lbfgs..........................\n","[CV 1/5; 2/42] END C=0.001, penalty=l1, solver=lbfgs;, score=nan total time=   0.2s\n","[CV 2/5; 2/42] START C=0.001, penalty=l1, solver=lbfgs..........................\n","[CV 2/5; 2/42] END C=0.001, penalty=l1, solver=lbfgs;, score=nan total time=   0.2s\n","[CV 3/5; 2/42] START C=0.001, penalty=l1, solver=lbfgs..........................\n","[CV 3/5; 2/42] END C=0.001, penalty=l1, solver=lbfgs;, score=nan total time=   0.2s\n","[CV 4/5; 2/42] START C=0.001, penalty=l1, solver=lbfgs..........................\n","[CV 4/5; 2/42] END C=0.001, penalty=l1, solver=lbfgs;, score=nan total time=   0.2s\n","[CV 5/5; 2/42] START C=0.001, penalty=l1, solver=lbfgs..........................\n","[CV 5/5; 2/42] END C=0.001, penalty=l1, solver=lbfgs;, score=nan total time=   0.2s\n","[CV 1/5; 3/42] START C=0.001, penalty=l1, solver=liblinear......................\n","[CV 1/5; 3/42] END C=0.001, penalty=l1, solver=liblinear;, score=0.053 total time=   0.5s\n","[CV 2/5; 3/42] START C=0.001, penalty=l1, solver=liblinear......................\n","[CV 2/5; 3/42] END C=0.001, penalty=l1, solver=liblinear;, score=0.053 total time=   0.3s\n","[CV 3/5; 3/42] START C=0.001, penalty=l1, solver=liblinear......................\n","[CV 3/5; 3/42] END C=0.001, penalty=l1, solver=liblinear;, score=0.053 total time=   0.3s\n","[CV 4/5; 3/42] START C=0.001, penalty=l1, solver=liblinear......................\n","[CV 4/5; 3/42] END C=0.001, penalty=l1, solver=liblinear;, score=0.053 total time=   0.3s\n","[CV 5/5; 3/42] START C=0.001, penalty=l1, solver=liblinear......................\n","[CV 5/5; 3/42] END C=0.001, penalty=l1, solver=liblinear;, score=0.069 total time=   0.5s\n","[CV 1/5; 4/42] START C=0.001, penalty=l2, solver=newton-cg......................\n","[CV 1/5; 4/42] END C=0.001, penalty=l2, solver=newton-cg;, score=0.486 total time=   0.3s\n","[CV 2/5; 4/42] START C=0.001, penalty=l2, solver=newton-cg......................\n","[CV 2/5; 4/42] END C=0.001, penalty=l2, solver=newton-cg;, score=0.486 total time=   0.3s\n","[CV 3/5; 4/42] START C=0.001, penalty=l2, solver=newton-cg......................\n","[CV 3/5; 4/42] END C=0.001, penalty=l2, solver=newton-cg;, score=0.486 total time=   0.3s\n","[CV 4/5; 4/42] START C=0.001, penalty=l2, solver=newton-cg......................\n","[CV 4/5; 4/42] END C=0.001, penalty=l2, solver=newton-cg;, score=0.486 total time=   0.5s\n","[CV 5/5; 4/42] START C=0.001, penalty=l2, solver=newton-cg......................\n","[CV 5/5; 4/42] END C=0.001, penalty=l2, solver=newton-cg;, score=0.481 total time=   0.3s\n","[CV 1/5; 5/42] START C=0.001, penalty=l2, solver=lbfgs..........................\n","[CV 1/5; 5/42] END C=0.001, penalty=l2, solver=lbfgs;, score=0.486 total time=   0.3s\n","[CV 2/5; 5/42] START C=0.001, penalty=l2, solver=lbfgs..........................\n","[CV 2/5; 5/42] END C=0.001, penalty=l2, solver=lbfgs;, score=0.486 total time=   0.3s\n","[CV 3/5; 5/42] START C=0.001, penalty=l2, solver=lbfgs..........................\n","[CV 3/5; 5/42] END C=0.001, penalty=l2, solver=lbfgs;, score=0.486 total time=   0.5s\n","[CV 4/5; 5/42] START C=0.001, penalty=l2, solver=lbfgs..........................\n","[CV 4/5; 5/42] END C=0.001, penalty=l2, solver=lbfgs;, score=0.486 total time=   0.3s\n","[CV 5/5; 5/42] START C=0.001, penalty=l2, solver=lbfgs..........................\n","[CV 5/5; 5/42] END C=0.001, penalty=l2, solver=lbfgs;, score=0.481 total time=   0.3s\n","[CV 1/5; 6/42] START C=0.001, penalty=l2, solver=liblinear......................\n","[CV 1/5; 6/42] END C=0.001, penalty=l2, solver=liblinear;, score=0.486 total time=   0.5s\n","[CV 2/5; 6/42] START C=0.001, penalty=l2, solver=liblinear......................\n","[CV 2/5; 6/42] END C=0.001, penalty=l2, solver=liblinear;, score=0.486 total time=   0.3s\n","[CV 3/5; 6/42] START C=0.001, penalty=l2, solver=liblinear......................\n","[CV 3/5; 6/42] END C=0.001, penalty=l2, solver=liblinear;, score=0.486 total time=   0.3s\n","[CV 4/5; 6/42] START C=0.001, penalty=l2, solver=liblinear......................\n","[CV 4/5; 6/42] END C=0.001, penalty=l2, solver=liblinear;, score=0.486 total time=   0.3s\n","[CV 5/5; 6/42] START C=0.001, penalty=l2, solver=liblinear......................\n","[CV 5/5; 6/42] END C=0.001, penalty=l2, solver=liblinear;, score=0.481 total time=   0.7s\n","[CV 1/5; 7/42] START C=0.01, penalty=l1, solver=newton-cg.......................\n","[CV 1/5; 7/42] END C=0.01, penalty=l1, solver=newton-cg;, score=nan total time=   0.3s\n","[CV 2/5; 7/42] START C=0.01, penalty=l1, solver=newton-cg.......................\n","[CV 2/5; 7/42] END C=0.01, penalty=l1, solver=newton-cg;, score=nan total time=   0.3s\n","[CV 3/5; 7/42] START C=0.01, penalty=l1, solver=newton-cg.......................\n","[CV 3/5; 7/42] END C=0.01, penalty=l1, solver=newton-cg;, score=nan total time=   0.3s\n","[CV 4/5; 7/42] START C=0.01, penalty=l1, solver=newton-cg.......................\n","[CV 4/5; 7/42] END C=0.01, penalty=l1, solver=newton-cg;, score=nan total time=   0.3s\n","[CV 5/5; 7/42] START C=0.01, penalty=l1, solver=newton-cg.......................\n","[CV 5/5; 7/42] END C=0.01, penalty=l1, solver=newton-cg;, score=nan total time=   0.3s\n","[CV 1/5; 8/42] START C=0.01, penalty=l1, solver=lbfgs...........................\n","[CV 1/5; 8/42] END C=0.01, penalty=l1, solver=lbfgs;, score=nan total time=   0.3s\n","[CV 2/5; 8/42] START C=0.01, penalty=l1, solver=lbfgs...........................\n","[CV 2/5; 8/42] END C=0.01, penalty=l1, solver=lbfgs;, score=nan total time=   0.3s\n","[CV 3/5; 8/42] START C=0.01, penalty=l1, solver=lbfgs...........................\n","[CV 3/5; 8/42] END C=0.01, penalty=l1, solver=lbfgs;, score=nan total time=   0.3s\n","[CV 4/5; 8/42] START C=0.01, penalty=l1, solver=lbfgs...........................\n","[CV 4/5; 8/42] END C=0.01, penalty=l1, solver=lbfgs;, score=nan total time=   0.2s\n","[CV 5/5; 8/42] START C=0.01, penalty=l1, solver=lbfgs...........................\n","[CV 5/5; 8/42] END C=0.01, penalty=l1, solver=lbfgs;, score=nan total time=   0.2s\n","[CV 1/5; 9/42] START C=0.01, penalty=l1, solver=liblinear.......................\n","[CV 1/5; 9/42] END C=0.01, penalty=l1, solver=liblinear;, score=0.053 total time=   0.3s\n","[CV 2/5; 9/42] START C=0.01, penalty=l1, solver=liblinear.......................\n","[CV 2/5; 9/42] END C=0.01, penalty=l1, solver=liblinear;, score=0.053 total time=   0.3s\n","[CV 3/5; 9/42] START C=0.01, penalty=l1, solver=liblinear.......................\n","[CV 3/5; 9/42] END C=0.01, penalty=l1, solver=liblinear;, score=0.053 total time=   0.5s\n","[CV 4/5; 9/42] START C=0.01, penalty=l1, solver=liblinear.......................\n","[CV 4/5; 9/42] END C=0.01, penalty=l1, solver=liblinear;, score=0.053 total time=   0.3s\n","[CV 5/5; 9/42] START C=0.01, penalty=l1, solver=liblinear.......................\n","[CV 5/5; 9/42] END C=0.01, penalty=l1, solver=liblinear;, score=0.069 total time=   0.3s\n","[CV 1/5; 10/42] START C=0.01, penalty=l2, solver=newton-cg......................\n","[CV 1/5; 10/42] END C=0.01, penalty=l2, solver=newton-cg;, score=0.486 total time=   0.3s\n","[CV 2/5; 10/42] START C=0.01, penalty=l2, solver=newton-cg......................\n","[CV 2/5; 10/42] END C=0.01, penalty=l2, solver=newton-cg;, score=0.486 total time=   0.5s\n","[CV 3/5; 10/42] START C=0.01, penalty=l2, solver=newton-cg......................\n","[CV 3/5; 10/42] END C=0.01, penalty=l2, solver=newton-cg;, score=0.486 total time=   0.3s\n","[CV 4/5; 10/42] START C=0.01, penalty=l2, solver=newton-cg......................\n","[CV 4/5; 10/42] END C=0.01, penalty=l2, solver=newton-cg;, score=0.486 total time=   0.3s\n","[CV 5/5; 10/42] START C=0.01, penalty=l2, solver=newton-cg......................\n","[CV 5/5; 10/42] END C=0.01, penalty=l2, solver=newton-cg;, score=0.481 total time=   1.0s\n","[CV 1/5; 11/42] START C=0.01, penalty=l2, solver=lbfgs..........................\n","[CV 1/5; 11/42] END C=0.01, penalty=l2, solver=lbfgs;, score=0.486 total time=   0.5s\n","[CV 2/5; 11/42] START C=0.01, penalty=l2, solver=lbfgs..........................\n","[CV 2/5; 11/42] END C=0.01, penalty=l2, solver=lbfgs;, score=0.486 total time=   0.3s\n","[CV 3/5; 11/42] START C=0.01, penalty=l2, solver=lbfgs..........................\n","[CV 3/5; 11/42] END C=0.01, penalty=l2, solver=lbfgs;, score=0.486 total time=   0.3s\n","[CV 4/5; 11/42] START C=0.01, penalty=l2, solver=lbfgs..........................\n","[CV 4/5; 11/42] END C=0.01, penalty=l2, solver=lbfgs;, score=0.486 total time=   0.5s\n","[CV 5/5; 11/42] START C=0.01, penalty=l2, solver=lbfgs..........................\n","[CV 5/5; 11/42] END C=0.01, penalty=l2, solver=lbfgs;, score=0.481 total time=   0.3s\n","[CV 1/5; 12/42] START C=0.01, penalty=l2, solver=liblinear......................\n","[CV 1/5; 12/42] END C=0.01, penalty=l2, solver=liblinear;, score=0.486 total time=   0.3s\n","[CV 2/5; 12/42] START C=0.01, penalty=l2, solver=liblinear......................\n","[CV 2/5; 12/42] END C=0.01, penalty=l2, solver=liblinear;, score=0.486 total time=   0.3s\n","[CV 3/5; 12/42] START C=0.01, penalty=l2, solver=liblinear......................\n","[CV 3/5; 12/42] END C=0.01, penalty=l2, solver=liblinear;, score=0.486 total time=   0.9s\n","[CV 4/5; 12/42] START C=0.01, penalty=l2, solver=liblinear......................\n","[CV 4/5; 12/42] END C=0.01, penalty=l2, solver=liblinear;, score=0.486 total time=   0.7s\n","[CV 5/5; 12/42] START C=0.01, penalty=l2, solver=liblinear......................\n","[CV 5/5; 12/42] END C=0.01, penalty=l2, solver=liblinear;, score=0.481 total time=   0.6s\n","[CV 1/5; 13/42] START C=0.1, penalty=l1, solver=newton-cg.......................\n","[CV 1/5; 13/42] END C=0.1, penalty=l1, solver=newton-cg;, score=nan total time=   0.4s\n","[CV 2/5; 13/42] START C=0.1, penalty=l1, solver=newton-cg.......................\n","[CV 2/5; 13/42] END C=0.1, penalty=l1, solver=newton-cg;, score=nan total time=   0.3s\n","[CV 3/5; 13/42] START C=0.1, penalty=l1, solver=newton-cg.......................\n","[CV 3/5; 13/42] END C=0.1, penalty=l1, solver=newton-cg;, score=nan total time=   0.2s\n","[CV 4/5; 13/42] START C=0.1, penalty=l1, solver=newton-cg.......................\n","[CV 4/5; 13/42] END C=0.1, penalty=l1, solver=newton-cg;, score=nan total time=   0.2s\n","[CV 5/5; 13/42] START C=0.1, penalty=l1, solver=newton-cg.......................\n","[CV 5/5; 13/42] END C=0.1, penalty=l1, solver=newton-cg;, score=nan total time=   0.5s\n","[CV 1/5; 14/42] START C=0.1, penalty=l1, solver=lbfgs...........................\n","[CV 1/5; 14/42] END C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.3s\n","[CV 2/5; 14/42] START C=0.1, penalty=l1, solver=lbfgs...........................\n","[CV 2/5; 14/42] END C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.3s\n","[CV 3/5; 14/42] START C=0.1, penalty=l1, solver=lbfgs...........................\n","[CV 3/5; 14/42] END C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.3s\n","[CV 4/5; 14/42] START C=0.1, penalty=l1, solver=lbfgs...........................\n","[CV 4/5; 14/42] END C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.3s\n","[CV 5/5; 14/42] START C=0.1, penalty=l1, solver=lbfgs...........................\n","[CV 5/5; 14/42] END C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.3s\n","[CV 1/5; 15/42] START C=0.1, penalty=l1, solver=liblinear.......................\n","[CV 1/5; 15/42] END C=0.1, penalty=l1, solver=liblinear;, score=0.486 total time=   0.4s\n","[CV 2/5; 15/42] START C=0.1, penalty=l1, solver=liblinear.......................\n","[CV 2/5; 15/42] END C=0.1, penalty=l1, solver=liblinear;, score=0.486 total time=   0.4s\n","[CV 3/5; 15/42] START C=0.1, penalty=l1, solver=liblinear.......................\n","[CV 3/5; 15/42] END C=0.1, penalty=l1, solver=liblinear;, score=0.486 total time=   0.4s\n","[CV 4/5; 15/42] START C=0.1, penalty=l1, solver=liblinear.......................\n","[CV 4/5; 15/42] END C=0.1, penalty=l1, solver=liblinear;, score=0.486 total time=   0.5s\n","[CV 5/5; 15/42] START C=0.1, penalty=l1, solver=liblinear.......................\n","[CV 5/5; 15/42] END C=0.1, penalty=l1, solver=liblinear;, score=0.481 total time=   0.3s\n","[CV 1/5; 16/42] START C=0.1, penalty=l2, solver=newton-cg.......................\n","[CV 1/5; 16/42] END C=0.1, penalty=l2, solver=newton-cg;, score=0.486 total time=   0.3s\n","[CV 2/5; 16/42] START C=0.1, penalty=l2, solver=newton-cg.......................\n","[CV 2/5; 16/42] END C=0.1, penalty=l2, solver=newton-cg;, score=0.486 total time=   0.5s\n","[CV 3/5; 16/42] START C=0.1, penalty=l2, solver=newton-cg.......................\n","[CV 3/5; 16/42] END C=0.1, penalty=l2, solver=newton-cg;, score=0.486 total time=   0.3s\n","[CV 4/5; 16/42] START C=0.1, penalty=l2, solver=newton-cg.......................\n","[CV 4/5; 16/42] END C=0.1, penalty=l2, solver=newton-cg;, score=0.486 total time=   0.3s\n","[CV 5/5; 16/42] START C=0.1, penalty=l2, solver=newton-cg.......................\n","[CV 5/5; 16/42] END C=0.1, penalty=l2, solver=newton-cg;, score=0.481 total time=   0.3s\n","[CV 1/5; 17/42] START C=0.1, penalty=l2, solver=lbfgs...........................\n","[CV 1/5; 17/42] END C=0.1, penalty=l2, solver=lbfgs;, score=0.486 total time=   0.6s\n","[CV 2/5; 17/42] START C=0.1, penalty=l2, solver=lbfgs...........................\n","[CV 2/5; 17/42] END C=0.1, penalty=l2, solver=lbfgs;, score=0.486 total time=   0.3s\n","[CV 3/5; 17/42] START C=0.1, penalty=l2, solver=lbfgs...........................\n","[CV 3/5; 17/42] END C=0.1, penalty=l2, solver=lbfgs;, score=0.486 total time=   0.3s\n","[CV 4/5; 17/42] START C=0.1, penalty=l2, solver=lbfgs...........................\n","[CV 4/5; 17/42] END C=0.1, penalty=l2, solver=lbfgs;, score=0.486 total time=   0.3s\n","[CV 5/5; 17/42] START C=0.1, penalty=l2, solver=lbfgs...........................\n","[CV 5/5; 17/42] END C=0.1, penalty=l2, solver=lbfgs;, score=0.481 total time=   0.5s\n","[CV 1/5; 18/42] START C=0.1, penalty=l2, solver=liblinear.......................\n","[CV 1/5; 18/42] END C=0.1, penalty=l2, solver=liblinear;, score=0.486 total time=   0.3s\n","[CV 2/5; 18/42] START C=0.1, penalty=l2, solver=liblinear.......................\n","[CV 2/5; 18/42] END C=0.1, penalty=l2, solver=liblinear;, score=0.486 total time=   0.3s\n","[CV 3/5; 18/42] START C=0.1, penalty=l2, solver=liblinear.......................\n","[CV 3/5; 18/42] END C=0.1, penalty=l2, solver=liblinear;, score=0.486 total time=   0.5s\n","[CV 4/5; 18/42] START C=0.1, penalty=l2, solver=liblinear.......................\n","[CV 4/5; 18/42] END C=0.1, penalty=l2, solver=liblinear;, score=0.486 total time=   0.3s\n","[CV 5/5; 18/42] START C=0.1, penalty=l2, solver=liblinear.......................\n","[CV 5/5; 18/42] END C=0.1, penalty=l2, solver=liblinear;, score=0.481 total time=   0.3s\n","[CV 1/5; 19/42] START C=1.0, penalty=l1, solver=newton-cg.......................\n","[CV 1/5; 19/42] END C=1.0, penalty=l1, solver=newton-cg;, score=nan total time=   0.2s\n","[CV 2/5; 19/42] START C=1.0, penalty=l1, solver=newton-cg.......................\n","[CV 2/5; 19/42] END C=1.0, penalty=l1, solver=newton-cg;, score=nan total time=   0.2s\n","[CV 3/5; 19/42] START C=1.0, penalty=l1, solver=newton-cg.......................\n","[CV 3/5; 19/42] END C=1.0, penalty=l1, solver=newton-cg;, score=nan total time=   0.2s\n","[CV 4/5; 19/42] START C=1.0, penalty=l1, solver=newton-cg.......................\n","[CV 4/5; 19/42] END C=1.0, penalty=l1, solver=newton-cg;, score=nan total time=   0.2s\n","[CV 5/5; 19/42] START C=1.0, penalty=l1, solver=newton-cg.......................\n","[CV 5/5; 19/42] END C=1.0, penalty=l1, solver=newton-cg;, score=nan total time=   0.2s\n","[CV 1/5; 20/42] START C=1.0, penalty=l1, solver=lbfgs...........................\n","[CV 1/5; 20/42] END C=1.0, penalty=l1, solver=lbfgs;, score=nan total time=   0.2s\n","[CV 2/5; 20/42] START C=1.0, penalty=l1, solver=lbfgs...........................\n","[CV 2/5; 20/42] END C=1.0, penalty=l1, solver=lbfgs;, score=nan total time=   0.2s\n","[CV 3/5; 20/42] START C=1.0, penalty=l1, solver=lbfgs...........................\n","[CV 3/5; 20/42] END C=1.0, penalty=l1, solver=lbfgs;, score=nan total time=   0.2s\n","[CV 4/5; 20/42] START C=1.0, penalty=l1, solver=lbfgs...........................\n","[CV 4/5; 20/42] END C=1.0, penalty=l1, solver=lbfgs;, score=nan total time=   0.2s\n","[CV 5/5; 20/42] START C=1.0, penalty=l1, solver=lbfgs...........................\n","[CV 5/5; 20/42] END C=1.0, penalty=l1, solver=lbfgs;, score=nan total time=   0.2s\n","[CV 1/5; 21/42] START C=1.0, penalty=l1, solver=liblinear.......................\n","[CV 1/5; 21/42] END C=1.0, penalty=l1, solver=liblinear;, score=0.486 total time=   0.5s\n","[CV 2/5; 21/42] START C=1.0, penalty=l1, solver=liblinear.......................\n","[CV 2/5; 21/42] END C=1.0, penalty=l1, solver=liblinear;, score=0.486 total time=   0.3s\n","[CV 3/5; 21/42] START C=1.0, penalty=l1, solver=liblinear.......................\n","[CV 3/5; 21/42] END C=1.0, penalty=l1, solver=liblinear;, score=0.486 total time=   0.3s\n","[CV 4/5; 21/42] START C=1.0, penalty=l1, solver=liblinear.......................\n","[CV 4/5; 21/42] END C=1.0, penalty=l1, solver=liblinear;, score=0.486 total time=   0.5s\n","[CV 5/5; 21/42] START C=1.0, penalty=l1, solver=liblinear.......................\n","[CV 5/5; 21/42] END C=1.0, penalty=l1, solver=liblinear;, score=0.481 total time=   0.3s\n","[CV 1/5; 22/42] START C=1.0, penalty=l2, solver=newton-cg.......................\n","[CV 1/5; 22/42] END C=1.0, penalty=l2, solver=newton-cg;, score=0.486 total time=   0.3s\n","[CV 2/5; 22/42] START C=1.0, penalty=l2, solver=newton-cg.......................\n","[CV 2/5; 22/42] END C=1.0, penalty=l2, solver=newton-cg;, score=0.486 total time=   0.4s\n","[CV 3/5; 22/42] START C=1.0, penalty=l2, solver=newton-cg.......................\n","[CV 3/5; 22/42] END C=1.0, penalty=l2, solver=newton-cg;, score=0.486 total time=   0.8s\n","[CV 4/5; 22/42] START C=1.0, penalty=l2, solver=newton-cg.......................\n","[CV 4/5; 22/42] END C=1.0, penalty=l2, solver=newton-cg;, score=0.486 total time=   0.5s\n","[CV 5/5; 22/42] START C=1.0, penalty=l2, solver=newton-cg.......................\n","[CV 5/5; 22/42] END C=1.0, penalty=l2, solver=newton-cg;, score=0.481 total time=   0.5s\n","[CV 1/5; 23/42] START C=1.0, penalty=l2, solver=lbfgs...........................\n","[CV 1/5; 23/42] END C=1.0, penalty=l2, solver=lbfgs;, score=0.486 total time=   0.4s\n","[CV 2/5; 23/42] START C=1.0, penalty=l2, solver=lbfgs...........................\n","[CV 2/5; 23/42] END C=1.0, penalty=l2, solver=lbfgs;, score=0.486 total time=   0.7s\n","[CV 3/5; 23/42] START C=1.0, penalty=l2, solver=lbfgs...........................\n","[CV 3/5; 23/42] END C=1.0, penalty=l2, solver=lbfgs;, score=0.486 total time=   0.3s\n","[CV 4/5; 23/42] START C=1.0, penalty=l2, solver=lbfgs...........................\n","[CV 4/5; 23/42] END C=1.0, penalty=l2, solver=lbfgs;, score=0.486 total time=   0.3s\n","[CV 5/5; 23/42] START C=1.0, penalty=l2, solver=lbfgs...........................\n","[CV 5/5; 23/42] END C=1.0, penalty=l2, solver=lbfgs;, score=0.481 total time=   0.5s\n","[CV 1/5; 24/42] START C=1.0, penalty=l2, solver=liblinear.......................\n","[CV 1/5; 24/42] END C=1.0, penalty=l2, solver=liblinear;, score=0.486 total time=   0.3s\n","[CV 2/5; 24/42] START C=1.0, penalty=l2, solver=liblinear.......................\n","[CV 2/5; 24/42] END C=1.0, penalty=l2, solver=liblinear;, score=0.486 total time=   0.3s\n","[CV 3/5; 24/42] START C=1.0, penalty=l2, solver=liblinear.......................\n","[CV 3/5; 24/42] END C=1.0, penalty=l2, solver=liblinear;, score=0.486 total time=   0.3s\n","[CV 4/5; 24/42] START C=1.0, penalty=l2, solver=liblinear.......................\n","[CV 4/5; 24/42] END C=1.0, penalty=l2, solver=liblinear;, score=0.486 total time=   0.5s\n","[CV 5/5; 24/42] START C=1.0, penalty=l2, solver=liblinear.......................\n","[CV 5/5; 24/42] END C=1.0, penalty=l2, solver=liblinear;, score=0.481 total time=   0.3s\n","[CV 1/5; 25/42] START C=10.0, penalty=l1, solver=newton-cg......................\n","[CV 1/5; 25/42] END C=10.0, penalty=l1, solver=newton-cg;, score=nan total time=   0.2s\n","[CV 2/5; 25/42] START C=10.0, penalty=l1, solver=newton-cg......................\n","[CV 2/5; 25/42] END C=10.0, penalty=l1, solver=newton-cg;, score=nan total time=   0.2s\n","[CV 3/5; 25/42] START C=10.0, penalty=l1, solver=newton-cg......................\n","[CV 3/5; 25/42] END C=10.0, penalty=l1, solver=newton-cg;, score=nan total time=   0.2s\n","[CV 4/5; 25/42] START C=10.0, penalty=l1, solver=newton-cg......................\n","[CV 4/5; 25/42] END C=10.0, penalty=l1, solver=newton-cg;, score=nan total time=   0.2s\n","[CV 5/5; 25/42] START C=10.0, penalty=l1, solver=newton-cg......................\n","[CV 5/5; 25/42] END C=10.0, penalty=l1, solver=newton-cg;, score=nan total time=   0.2s\n","[CV 1/5; 26/42] START C=10.0, penalty=l1, solver=lbfgs..........................\n","[CV 1/5; 26/42] END C=10.0, penalty=l1, solver=lbfgs;, score=nan total time=   0.2s\n","[CV 2/5; 26/42] START C=10.0, penalty=l1, solver=lbfgs..........................\n","[CV 2/5; 26/42] END C=10.0, penalty=l1, solver=lbfgs;, score=nan total time=   0.2s\n","[CV 3/5; 26/42] START C=10.0, penalty=l1, solver=lbfgs..........................\n","[CV 3/5; 26/42] END C=10.0, penalty=l1, solver=lbfgs;, score=nan total time=   0.2s\n","[CV 4/5; 26/42] START C=10.0, penalty=l1, solver=lbfgs..........................\n","[CV 4/5; 26/42] END C=10.0, penalty=l1, solver=lbfgs;, score=nan total time=   0.2s\n","[CV 5/5; 26/42] START C=10.0, penalty=l1, solver=lbfgs..........................\n","[CV 5/5; 26/42] END C=10.0, penalty=l1, solver=lbfgs;, score=nan total time=   0.2s\n","[CV 1/5; 27/42] START C=10.0, penalty=l1, solver=liblinear......................\n","[CV 1/5; 27/42] END C=10.0, penalty=l1, solver=liblinear;, score=0.740 total time=   0.3s\n","[CV 2/5; 27/42] START C=10.0, penalty=l1, solver=liblinear......................\n","[CV 2/5; 27/42] END C=10.0, penalty=l1, solver=liblinear;, score=0.740 total time=   0.5s\n","[CV 3/5; 27/42] START C=10.0, penalty=l1, solver=liblinear......................\n","[CV 3/5; 27/42] END C=10.0, penalty=l1, solver=liblinear;, score=0.740 total time=   0.3s\n","[CV 4/5; 27/42] START C=10.0, penalty=l1, solver=liblinear......................\n","[CV 4/5; 27/42] END C=10.0, penalty=l1, solver=liblinear;, score=0.685 total time=   0.3s\n","[CV 5/5; 27/42] START C=10.0, penalty=l1, solver=liblinear......................\n","[CV 5/5; 27/42] END C=10.0, penalty=l1, solver=liblinear;, score=0.771 total time=   0.5s\n","[CV 1/5; 28/42] START C=10.0, penalty=l2, solver=newton-cg......................\n","[CV 1/5; 28/42] END C=10.0, penalty=l2, solver=newton-cg;, score=0.486 total time=   0.3s\n","[CV 2/5; 28/42] START C=10.0, penalty=l2, solver=newton-cg......................\n","[CV 2/5; 28/42] END C=10.0, penalty=l2, solver=newton-cg;, score=0.486 total time=   0.3s\n","[CV 3/5; 28/42] START C=10.0, penalty=l2, solver=newton-cg......................\n","[CV 3/5; 28/42] END C=10.0, penalty=l2, solver=newton-cg;, score=0.740 total time=   0.3s\n","[CV 4/5; 28/42] START C=10.0, penalty=l2, solver=newton-cg......................\n","[CV 4/5; 28/42] END C=10.0, penalty=l2, solver=newton-cg;, score=0.486 total time=   0.6s\n","[CV 5/5; 28/42] START C=10.0, penalty=l2, solver=newton-cg......................\n","[CV 5/5; 28/42] END C=10.0, penalty=l2, solver=newton-cg;, score=0.824 total time=   0.3s\n","[CV 1/5; 29/42] START C=10.0, penalty=l2, solver=lbfgs..........................\n","[CV 1/5; 29/42] END C=10.0, penalty=l2, solver=lbfgs;, score=0.486 total time=   0.3s\n","[CV 2/5; 29/42] START C=10.0, penalty=l2, solver=lbfgs..........................\n","[CV 2/5; 29/42] END C=10.0, penalty=l2, solver=lbfgs;, score=0.486 total time=   0.5s\n","[CV 3/5; 29/42] START C=10.0, penalty=l2, solver=lbfgs..........................\n","[CV 3/5; 29/42] END C=10.0, penalty=l2, solver=lbfgs;, score=0.740 total time=   0.3s\n","[CV 4/5; 29/42] START C=10.0, penalty=l2, solver=lbfgs..........................\n","[CV 4/5; 29/42] END C=10.0, penalty=l2, solver=lbfgs;, score=0.486 total time=   0.3s\n","[CV 5/5; 29/42] START C=10.0, penalty=l2, solver=lbfgs..........................\n","[CV 5/5; 29/42] END C=10.0, penalty=l2, solver=lbfgs;, score=0.824 total time=   0.3s\n","[CV 1/5; 30/42] START C=10.0, penalty=l2, solver=liblinear......................\n","[CV 1/5; 30/42] END C=10.0, penalty=l2, solver=liblinear;, score=0.486 total time=   0.7s\n","[CV 2/5; 30/42] START C=10.0, penalty=l2, solver=liblinear......................\n","[CV 2/5; 30/42] END C=10.0, penalty=l2, solver=liblinear;, score=0.486 total time=   0.4s\n","[CV 3/5; 30/42] START C=10.0, penalty=l2, solver=liblinear......................\n","[CV 3/5; 30/42] END C=10.0, penalty=l2, solver=liblinear;, score=0.740 total time=   0.5s\n","[CV 4/5; 30/42] START C=10.0, penalty=l2, solver=liblinear......................\n","[CV 4/5; 30/42] END C=10.0, penalty=l2, solver=liblinear;, score=0.486 total time=   0.4s\n","[CV 5/5; 30/42] START C=10.0, penalty=l2, solver=liblinear......................\n","[CV 5/5; 30/42] END C=10.0, penalty=l2, solver=liblinear;, score=0.824 total time=   0.8s\n","[CV 1/5; 31/42] START C=100.0, penalty=l1, solver=newton-cg.....................\n","[CV 1/5; 31/42] END C=100.0, penalty=l1, solver=newton-cg;, score=nan total time=   0.2s\n","[CV 2/5; 31/42] START C=100.0, penalty=l1, solver=newton-cg.....................\n","[CV 2/5; 31/42] END C=100.0, penalty=l1, solver=newton-cg;, score=nan total time=   0.2s\n","[CV 3/5; 31/42] START C=100.0, penalty=l1, solver=newton-cg.....................\n","[CV 3/5; 31/42] END C=100.0, penalty=l1, solver=newton-cg;, score=nan total time=   0.2s\n","[CV 4/5; 31/42] START C=100.0, penalty=l1, solver=newton-cg.....................\n","[CV 4/5; 31/42] END C=100.0, penalty=l1, solver=newton-cg;, score=nan total time=   0.2s\n","[CV 5/5; 31/42] START C=100.0, penalty=l1, solver=newton-cg.....................\n","[CV 5/5; 31/42] END C=100.0, penalty=l1, solver=newton-cg;, score=nan total time=   0.2s\n","[CV 1/5; 32/42] START C=100.0, penalty=l1, solver=lbfgs.........................\n","[CV 1/5; 32/42] END C=100.0, penalty=l1, solver=lbfgs;, score=nan total time=   0.2s\n","[CV 2/5; 32/42] START C=100.0, penalty=l1, solver=lbfgs.........................\n","[CV 2/5; 32/42] END C=100.0, penalty=l1, solver=lbfgs;, score=nan total time=   0.2s\n","[CV 3/5; 32/42] START C=100.0, penalty=l1, solver=lbfgs.........................\n","[CV 3/5; 32/42] END C=100.0, penalty=l1, solver=lbfgs;, score=nan total time=   0.2s\n","[CV 4/5; 32/42] START C=100.0, penalty=l1, solver=lbfgs.........................\n","[CV 4/5; 32/42] END C=100.0, penalty=l1, solver=lbfgs;, score=nan total time=   0.2s\n","[CV 5/5; 32/42] START C=100.0, penalty=l1, solver=lbfgs.........................\n","[CV 5/5; 32/42] END C=100.0, penalty=l1, solver=lbfgs;, score=nan total time=   0.2s\n","[CV 1/5; 33/42] START C=100.0, penalty=l1, solver=liblinear.....................\n","[CV 1/5; 33/42] END C=100.0, penalty=l1, solver=liblinear;, score=0.740 total time=   0.3s\n","[CV 2/5; 33/42] START C=100.0, penalty=l1, solver=liblinear.....................\n","[CV 2/5; 33/42] END C=100.0, penalty=l1, solver=liblinear;, score=0.740 total time=   0.3s\n","[CV 3/5; 33/42] START C=100.0, penalty=l1, solver=liblinear.....................\n","[CV 3/5; 33/42] END C=100.0, penalty=l1, solver=liblinear;, score=0.740 total time=   0.5s\n","[CV 4/5; 33/42] START C=100.0, penalty=l1, solver=liblinear.....................\n","[CV 4/5; 33/42] END C=100.0, penalty=l1, solver=liblinear;, score=0.740 total time=   0.3s\n","[CV 5/5; 33/42] START C=100.0, penalty=l1, solver=liblinear.....................\n","[CV 5/5; 33/42] END C=100.0, penalty=l1, solver=liblinear;, score=0.730 total time=   0.3s\n","[CV 1/5; 34/42] START C=100.0, penalty=l2, solver=newton-cg.....................\n","[CV 1/5; 34/42] END C=100.0, penalty=l2, solver=newton-cg;, score=0.486 total time=   0.5s\n","[CV 2/5; 34/42] START C=100.0, penalty=l2, solver=newton-cg.....................\n","[CV 2/5; 34/42] END C=100.0, penalty=l2, solver=newton-cg;, score=0.486 total time=   0.3s\n","[CV 3/5; 34/42] START C=100.0, penalty=l2, solver=newton-cg.....................\n","[CV 3/5; 34/42] END C=100.0, penalty=l2, solver=newton-cg;, score=0.740 total time=   0.3s\n","[CV 4/5; 34/42] START C=100.0, penalty=l2, solver=newton-cg.....................\n","[CV 4/5; 34/42] END C=100.0, penalty=l2, solver=newton-cg;, score=0.486 total time=   0.3s\n","[CV 5/5; 34/42] START C=100.0, penalty=l2, solver=newton-cg.....................\n","[CV 5/5; 34/42] END C=100.0, penalty=l2, solver=newton-cg;, score=0.824 total time=   0.6s\n","[CV 1/5; 35/42] START C=100.0, penalty=l2, solver=lbfgs.........................\n","[CV 1/5; 35/42] END C=100.0, penalty=l2, solver=lbfgs;, score=0.486 total time=   0.3s\n","[CV 2/5; 35/42] START C=100.0, penalty=l2, solver=lbfgs.........................\n","[CV 2/5; 35/42] END C=100.0, penalty=l2, solver=lbfgs;, score=0.486 total time=   0.3s\n","[CV 3/5; 35/42] START C=100.0, penalty=l2, solver=lbfgs.........................\n","[CV 3/5; 35/42] END C=100.0, penalty=l2, solver=lbfgs;, score=0.740 total time=   0.3s\n","[CV 4/5; 35/42] START C=100.0, penalty=l2, solver=lbfgs.........................\n","[CV 4/5; 35/42] END C=100.0, penalty=l2, solver=lbfgs;, score=0.486 total time=   0.6s\n","[CV 5/5; 35/42] START C=100.0, penalty=l2, solver=lbfgs.........................\n","[CV 5/5; 35/42] END C=100.0, penalty=l2, solver=lbfgs;, score=0.824 total time=   0.3s\n","[CV 1/5; 36/42] START C=100.0, penalty=l2, solver=liblinear.....................\n","[CV 1/5; 36/42] END C=100.0, penalty=l2, solver=liblinear;, score=0.486 total time=   0.3s\n","[CV 2/5; 36/42] START C=100.0, penalty=l2, solver=liblinear.....................\n","[CV 2/5; 36/42] END C=100.0, penalty=l2, solver=liblinear;, score=0.486 total time=   0.3s\n","[CV 3/5; 36/42] START C=100.0, penalty=l2, solver=liblinear.....................\n","[CV 3/5; 36/42] END C=100.0, penalty=l2, solver=liblinear;, score=0.740 total time=   0.5s\n","[CV 4/5; 36/42] START C=100.0, penalty=l2, solver=liblinear.....................\n","[CV 4/5; 36/42] END C=100.0, penalty=l2, solver=liblinear;, score=0.486 total time=   0.3s\n","[CV 5/5; 36/42] START C=100.0, penalty=l2, solver=liblinear.....................\n","[CV 5/5; 36/42] END C=100.0, penalty=l2, solver=liblinear;, score=0.824 total time=   0.3s\n","[CV 1/5; 37/42] START C=1000.0, penalty=l1, solver=newton-cg....................\n","[CV 1/5; 37/42] END C=1000.0, penalty=l1, solver=newton-cg;, score=nan total time=   0.2s\n","[CV 2/5; 37/42] START C=1000.0, penalty=l1, solver=newton-cg....................\n","[CV 2/5; 37/42] END C=1000.0, penalty=l1, solver=newton-cg;, score=nan total time=   0.2s\n","[CV 3/5; 37/42] START C=1000.0, penalty=l1, solver=newton-cg....................\n","[CV 3/5; 37/42] END C=1000.0, penalty=l1, solver=newton-cg;, score=nan total time=   0.2s\n","[CV 4/5; 37/42] START C=1000.0, penalty=l1, solver=newton-cg....................\n","[CV 4/5; 37/42] END C=1000.0, penalty=l1, solver=newton-cg;, score=nan total time=   0.2s\n","[CV 5/5; 37/42] START C=1000.0, penalty=l1, solver=newton-cg....................\n","[CV 5/5; 37/42] END C=1000.0, penalty=l1, solver=newton-cg;, score=nan total time=   0.2s\n","[CV 1/5; 38/42] START C=1000.0, penalty=l1, solver=lbfgs........................\n","[CV 1/5; 38/42] END C=1000.0, penalty=l1, solver=lbfgs;, score=nan total time=   0.2s\n","[CV 2/5; 38/42] START C=1000.0, penalty=l1, solver=lbfgs........................\n","[CV 2/5; 38/42] END C=1000.0, penalty=l1, solver=lbfgs;, score=nan total time=   0.2s\n","[CV 3/5; 38/42] START C=1000.0, penalty=l1, solver=lbfgs........................\n","[CV 3/5; 38/42] END C=1000.0, penalty=l1, solver=lbfgs;, score=nan total time=   0.5s\n","[CV 4/5; 38/42] START C=1000.0, penalty=l1, solver=lbfgs........................\n","[CV 4/5; 38/42] END C=1000.0, penalty=l1, solver=lbfgs;, score=nan total time=   0.3s\n","[CV 5/5; 38/42] START C=1000.0, penalty=l1, solver=lbfgs........................\n","[CV 5/5; 38/42] END C=1000.0, penalty=l1, solver=lbfgs;, score=nan total time=   0.3s\n","[CV 1/5; 39/42] START C=1000.0, penalty=l1, solver=liblinear....................\n","[CV 1/5; 39/42] END C=1000.0, penalty=l1, solver=liblinear;, score=0.685 total time=   0.4s\n","[CV 2/5; 39/42] START C=1000.0, penalty=l1, solver=liblinear....................\n","[CV 2/5; 39/42] END C=1000.0, penalty=l1, solver=liblinear;, score=0.740 total time=   0.5s\n","[CV 3/5; 39/42] START C=1000.0, penalty=l1, solver=liblinear....................\n","[CV 3/5; 39/42] END C=1000.0, penalty=l1, solver=liblinear;, score=0.740 total time=   0.4s\n","[CV 4/5; 39/42] START C=1000.0, penalty=l1, solver=liblinear....................\n","[CV 4/5; 39/42] END C=1000.0, penalty=l1, solver=liblinear;, score=0.740 total time=   0.7s\n","[CV 5/5; 39/42] START C=1000.0, penalty=l1, solver=liblinear....................\n","[CV 5/5; 39/42] END C=1000.0, penalty=l1, solver=liblinear;, score=0.730 total time=   0.3s\n","[CV 1/5; 40/42] START C=1000.0, penalty=l2, solver=newton-cg....................\n","[CV 1/5; 40/42] END C=1000.0, penalty=l2, solver=newton-cg;, score=0.486 total time=   0.3s\n","[CV 2/5; 40/42] START C=1000.0, penalty=l2, solver=newton-cg....................\n","[CV 2/5; 40/42] END C=1000.0, penalty=l2, solver=newton-cg;, score=0.486 total time=   0.3s\n","[CV 3/5; 40/42] START C=1000.0, penalty=l2, solver=newton-cg....................\n","[CV 3/5; 40/42] END C=1000.0, penalty=l2, solver=newton-cg;, score=0.740 total time=   0.6s\n","[CV 4/5; 40/42] START C=1000.0, penalty=l2, solver=newton-cg....................\n","[CV 4/5; 40/42] END C=1000.0, penalty=l2, solver=newton-cg;, score=0.486 total time=   0.3s\n","[CV 5/5; 40/42] START C=1000.0, penalty=l2, solver=newton-cg....................\n","[CV 5/5; 40/42] END C=1000.0, penalty=l2, solver=newton-cg;, score=0.824 total time=   0.3s\n","[CV 1/5; 41/42] START C=1000.0, penalty=l2, solver=lbfgs........................\n","[CV 1/5; 41/42] END C=1000.0, penalty=l2, solver=lbfgs;, score=0.486 total time=   0.5s\n","[CV 2/5; 41/42] START C=1000.0, penalty=l2, solver=lbfgs........................\n","[CV 2/5; 41/42] END C=1000.0, penalty=l2, solver=lbfgs;, score=0.486 total time=   0.3s\n","[CV 3/5; 41/42] START C=1000.0, penalty=l2, solver=lbfgs........................\n","[CV 3/5; 41/42] END C=1000.0, penalty=l2, solver=lbfgs;, score=0.740 total time=   0.3s\n","[CV 4/5; 41/42] START C=1000.0, penalty=l2, solver=lbfgs........................\n","[CV 4/5; 41/42] END C=1000.0, penalty=l2, solver=lbfgs;, score=0.486 total time=   0.3s\n","[CV 5/5; 41/42] START C=1000.0, penalty=l2, solver=lbfgs........................\n","[CV 5/5; 41/42] END C=1000.0, penalty=l2, solver=lbfgs;, score=0.824 total time=   0.6s\n","[CV 1/5; 42/42] START C=1000.0, penalty=l2, solver=liblinear....................\n","[CV 1/5; 42/42] END C=1000.0, penalty=l2, solver=liblinear;, score=0.486 total time=   0.3s\n","[CV 2/5; 42/42] START C=1000.0, penalty=l2, solver=liblinear....................\n","[CV 2/5; 42/42] END C=1000.0, penalty=l2, solver=liblinear;, score=0.486 total time=   0.3s\n","[CV 3/5; 42/42] START C=1000.0, penalty=l2, solver=liblinear....................\n","[CV 3/5; 42/42] END C=1000.0, penalty=l2, solver=liblinear;, score=0.740 total time=   0.3s\n","[CV 4/5; 42/42] START C=1000.0, penalty=l2, solver=liblinear....................\n","[CV 4/5; 42/42] END C=1000.0, penalty=l2, solver=liblinear;, score=0.486 total time=   0.5s\n","[CV 5/5; 42/42] START C=1000.0, penalty=l2, solver=liblinear....................\n","[CV 5/5; 42/42] END C=1000.0, penalty=l2, solver=liblinear;, score=0.824 total time=   0.3s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n","70 fits failed out of a total of 210.\n","The score on these train-test partitions for these parameters will be set to nan.\n","If these failures are not expected, you can try to debug them by setting error_score='raise'.\n","\n","Below are more details about the failures:\n","--------------------------------------------------------------------------------\n","35 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n","    solver = _check_solver(self.solver, self.penalty, self.dual)\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n","    raise ValueError(\n","ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","--------------------------------------------------------------------------------\n","35 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n","    solver = _check_solver(self.solver, self.penalty, self.dual)\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n","    raise ValueError(\n","ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","  warnings.warn(some_fits_failed_message, FitFailedWarning)\n","/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.05589837 0.48472527 0.48472527 0.48472527\n","        nan        nan 0.05589837 0.48472527 0.48472527 0.48472527\n","        nan        nan 0.48472527 0.48472527 0.48472527 0.48472527\n","        nan        nan 0.48472527 0.48472527 0.48472527 0.48472527\n","        nan        nan 0.73549071 0.60421138 0.60421138 0.60421138\n","        nan        nan 0.73830769 0.60421138 0.60421138 0.60421138\n","        nan        nan 0.72731815 0.60421138 0.60421138 0.60421138]\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=-3,\n","             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n","                         'penalty': ['l1', 'l2'],\n","                         'solver': ['newton-cg', 'lbfgs', 'liblinear']},\n","             scoring='f1_macro', verbose=10)"],"text/html":["<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=-3,\n","             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n","                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n","                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;]},\n","             scoring=&#x27;f1_macro&#x27;, verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=-3,\n","             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n","                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n","                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;]},\n","             scoring=&#x27;f1_macro&#x27;, verbose=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"]},"metadata":{},"execution_count":59}]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix, classification_report, f1_score"],"metadata":{"id":"y656EPAtr_l5","executionInfo":{"status":"ok","timestamp":1688175487088,"user_tz":360,"elapsed":21,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}}},"execution_count":60,"outputs":[]},{"cell_type":"code","source":["# Aplicando a los datos de test\n","y_pred_train = logreg_gs.best_estimator_.predict(df_x_train)\n","\n","# En la matriz de confusión vemos que\n","# logra predecir correctamente los 16 comentarios negativos\n","confusion_matrix(y_pred_train, y_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iU-tsCSQDaA4","executionInfo":{"status":"ok","timestamp":1688175487089,"user_tz":360,"elapsed":22,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}},"outputId":"1061a671-8ad3-4b6c-858a-207b0999844c"},"execution_count":61,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 16,   0],\n","       [  0, 254]])"]},"metadata":{},"execution_count":61}]},{"cell_type":"code","source":["print(classification_report(y_pred_train, y_train))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p_SohHRjEV5o","executionInfo":{"status":"ok","timestamp":1688175487292,"user_tz":360,"elapsed":221,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}},"outputId":"c252f024-b870-4044-dfde-39e48bb3cc13"},"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","         0.0       1.00      1.00      1.00        16\n","         1.0       1.00      1.00      1.00       254\n","\n","    accuracy                           1.00       270\n","   macro avg       1.00      1.00      1.00       270\n","weighted avg       1.00      1.00      1.00       270\n","\n"]}]},{"cell_type":"code","source":["y_pred_train = logreg_gs.best_estimator_.predict(df_x_train)"],"metadata":{"id":"prdlDQFMF4bU","executionInfo":{"status":"ok","timestamp":1688175487292,"user_tz":360,"elapsed":5,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}}},"execution_count":63,"outputs":[]},{"cell_type":"code","source":["train_score = f1_score(y_train, y_pred_train, average=\"macro\")\n","print(\"Tuned Hyperparameters :\", logreg_gs.best_params_)\n","# Los valores de f1-score van de 0 a 1, mientras\n","# más cercano sea a 1, mejor será el modelo\n","print(\"F1 score en Train:\", round(train_score, 2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cbDaTg8PjhiN","executionInfo":{"status":"ok","timestamp":1688175487293,"user_tz":360,"elapsed":5,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}},"outputId":"55bf3793-956c-4509-f287-82e4abe88987"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["Tuned Hyperparameters : {'C': 100.0, 'penalty': 'l1', 'solver': 'liblinear'}\n","F1 score en Train: 1.0\n"]}]},{"cell_type":"markdown","source":["Tiene un alto score, por lo que es posible que se encuentre sobre entrenado."],"metadata":{"id":"RDv0hLmeHD1D"}},{"cell_type":"markdown","source":["### Validation"],"metadata":{"id":"oUx_uuPCrhBJ"}},{"cell_type":"code","source":["# [1] Preprocesamiento (limpieza del texto)\n","test_processed = process_text(test)\n","# [2] Vectorización\n","x_test = test_processed[\"feature\"]\n","df_x_test = vectorize_features(x_test)\n","# Aplicando a los datos de test\n","y_pred_test = logreg_gs.best_estimator_.predict(df_x_test)"],"metadata":{"id":"tjhC-veCsD5w","executionInfo":{"status":"ok","timestamp":1688175686420,"user_tz":360,"elapsed":145,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}}},"execution_count":65,"outputs":[]},{"cell_type":"code","source":["test_processed = encode_categories(test)\n","y_test = test_processed[\"target\"]"],"metadata":{"id":"_nfklGyO5TDK","executionInfo":{"status":"ok","timestamp":1688175687983,"user_tz":360,"elapsed":147,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}}},"execution_count":66,"outputs":[]},{"cell_type":"code","source":["# En la matriz de confusión vemos que solo\n","# logra predecir 1 de los 4 comentarios negativos.\n","confusion_matrix(y_pred_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Wu5ksC1sBAd","executionInfo":{"status":"ok","timestamp":1688175693096,"user_tz":360,"elapsed":138,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}},"outputId":"53d2ddb9-ef7a-4f97-f224-02d2afdd9d14"},"execution_count":67,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 1,  0],\n","       [ 3, 64]])"]},"metadata":{},"execution_count":67}]},{"cell_type":"code","source":["print(classification_report(y_pred_test, y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UxvtdT2Bjn_6","executionInfo":{"status":"ok","timestamp":1688175705949,"user_tz":360,"elapsed":209,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}},"outputId":"c7b9fcd3-b13e-47de-a7d1-fc4ddc0da6b4"},"execution_count":69,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","         0.0       0.25      1.00      0.40         1\n","         1.0       1.00      0.96      0.98        67\n","\n","    accuracy                           0.96        68\n","   macro avg       0.62      0.98      0.69        68\n","weighted avg       0.99      0.96      0.97        68\n","\n"]}]},{"cell_type":"code","source":["test_score = f1_score(y_test, y_pred_test, average=\"macro\")"],"metadata":{"id":"pjGYDmCxtKhs","executionInfo":{"status":"ok","timestamp":1688175717987,"user_tz":360,"elapsed":146,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}}},"execution_count":70,"outputs":[]},{"cell_type":"code","source":["print(f\"Train score: {round(train_score, 2)} \\nTest score: {round(test_score, 2)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DeEE5JTGxsQc","executionInfo":{"status":"ok","timestamp":1688175719261,"user_tz":360,"elapsed":203,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}},"outputId":"26d44ec1-c0d8-485c-8b2e-309bb228959a"},"execution_count":71,"outputs":[{"output_type":"stream","name":"stdout","text":["Train score: 1.0 \n","Test score: 0.69\n"]}]},{"cell_type":"markdown","source":["El score de entrenamiento es muy alto, mientras que en los datos de test es de 0.7, es decir, más bajo, por lo que podemos determinar que hay overfitting.\n","\n","Este problema podrá tratarse en otra iteración, con el uso de más datos,aumentado el número de k-folds, o utilizando un ensamblado de modelos.\n","\n","Por ahora, el modelo tiene un desempeño acetable, ya que tiene un **score en los datos de Test de 69%**."],"metadata":{"id":"-id7okts5Y2q"}},{"cell_type":"code","source":["# Guardando el modelo\n","LR_ESTIMATOR_PATH = \"/content/lr_estimator\"\n","save_to_pickle(logreg_gs.best_estimator_, LR_ESTIMATOR_PATH)"],"metadata":{"id":"oKbepuDX7_ZW","executionInfo":{"status":"ok","timestamp":1688175837020,"user_tz":360,"elapsed":177,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}}},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":["## XGBoost"],"metadata":{"id":"KKrGjm0rxEov"}},{"cell_type":"code","source":["# import xgboost as xgb\n","from xgboost import XGBClassifier\n","from sklearn.model_selection import GridSearchCV"],"metadata":{"id":"SlfbYtwPX_9J","executionInfo":{"status":"ok","timestamp":1688175839888,"user_tz":360,"elapsed":310,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}}},"execution_count":74,"outputs":[]},{"cell_type":"code","source":["estimator = XGBClassifier(\n","    objective= 'binary:logistic',\n","    nthread=4,\n","    seed=42\n",")\n","\n","parameters = {\n","    'max_depth': range(2, 10, 1),\n","    'n_estimators': range(60, 220, 40),\n","    'learning_rate': [0.1, 0.01, 0.05]\n","}\n","\n","# En total se prueban 480 modelos\n","grid_search = GridSearchCV(\n","    estimator=estimator,\n","    param_grid=parameters,\n","    scoring=\"f1_macro\",\n","    cv=5,\n","    n_jobs=-1,\n","    verbose=10,\n",")\n","\n","grid_search.fit(df_x_train, y_train)\n","\n","#grid_search.best_estimator_"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":134},"id":"O1qtIJU1cVe4","executionInfo":{"status":"ok","timestamp":1688176557486,"user_tz":360,"elapsed":714272,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}},"outputId":"ae31fe93-40d7-405c-ce69-b9a6681fff44"},"execution_count":75,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"]},{"output_type":"execute_result","data":{"text/plain":["GridSearchCV(cv=5,\n","             estimator=XGBClassifier(base_score=None, booster=None,\n","                                     callbacks=None, colsample_bylevel=None,\n","                                     colsample_bynode=None,\n","                                     colsample_bytree=None,\n","                                     early_stopping_rounds=None,\n","                                     enable_categorical=False, eval_metric=None,\n","                                     feature_types=None, gamma=None,\n","                                     gpu_id=None, grow_policy=None,\n","                                     importance_type=None,\n","                                     interaction_constraints=None,\n","                                     learning_rate=None,...\n","                                     max_cat_to_onehot=None,\n","                                     max_delta_step=None, max_depth=None,\n","                                     max_leaves=None, min_child_weight=None,\n","                                     missing=nan, monotone_constraints=None,\n","                                     n_estimators=100, n_jobs=None, nthread=4,\n","                                     num_parallel_tree=None, predictor=None, ...),\n","             n_jobs=-1,\n","             param_grid={'learning_rate': [0.1, 0.01, 0.05],\n","                         'max_depth': range(2, 10),\n","                         'n_estimators': range(60, 220, 40)},\n","             scoring='f1_macro', verbose=10)"],"text/html":["<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n","             estimator=XGBClassifier(base_score=None, booster=None,\n","                                     callbacks=None, colsample_bylevel=None,\n","                                     colsample_bynode=None,\n","                                     colsample_bytree=None,\n","                                     early_stopping_rounds=None,\n","                                     enable_categorical=False, eval_metric=None,\n","                                     feature_types=None, gamma=None,\n","                                     gpu_id=None, grow_policy=None,\n","                                     importance_type=None,\n","                                     interaction_constraints=None,\n","                                     learning_rate=None,...\n","                                     max_cat_to_onehot=None,\n","                                     max_delta_step=None, max_depth=None,\n","                                     max_leaves=None, min_child_weight=None,\n","                                     missing=nan, monotone_constraints=None,\n","                                     n_estimators=100, n_jobs=None, nthread=4,\n","                                     num_parallel_tree=None, predictor=None, ...),\n","             n_jobs=-1,\n","             param_grid={&#x27;learning_rate&#x27;: [0.1, 0.01, 0.05],\n","                         &#x27;max_depth&#x27;: range(2, 10),\n","                         &#x27;n_estimators&#x27;: range(60, 220, 40)},\n","             scoring=&#x27;f1_macro&#x27;, verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n","             estimator=XGBClassifier(base_score=None, booster=None,\n","                                     callbacks=None, colsample_bylevel=None,\n","                                     colsample_bynode=None,\n","                                     colsample_bytree=None,\n","                                     early_stopping_rounds=None,\n","                                     enable_categorical=False, eval_metric=None,\n","                                     feature_types=None, gamma=None,\n","                                     gpu_id=None, grow_policy=None,\n","                                     importance_type=None,\n","                                     interaction_constraints=None,\n","                                     learning_rate=None,...\n","                                     max_cat_to_onehot=None,\n","                                     max_delta_step=None, max_depth=None,\n","                                     max_leaves=None, min_child_weight=None,\n","                                     missing=nan, monotone_constraints=None,\n","                                     n_estimators=100, n_jobs=None, nthread=4,\n","                                     num_parallel_tree=None, predictor=None, ...),\n","             n_jobs=-1,\n","             param_grid={&#x27;learning_rate&#x27;: [0.1, 0.01, 0.05],\n","                         &#x27;max_depth&#x27;: range(2, 10),\n","                         &#x27;n_estimators&#x27;: range(60, 220, 40)},\n","             scoring=&#x27;f1_macro&#x27;, verbose=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n","              colsample_bylevel=None, colsample_bynode=None,\n","              colsample_bytree=None, early_stopping_rounds=None,\n","              enable_categorical=False, eval_metric=None, feature_types=None,\n","              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n","              interaction_constraints=None, learning_rate=None, max_bin=None,\n","              max_cat_threshold=None, max_cat_to_onehot=None,\n","              max_delta_step=None, max_depth=None, max_leaves=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=None, nthread=4, num_parallel_tree=None,\n","              predictor=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n","              colsample_bylevel=None, colsample_bynode=None,\n","              colsample_bytree=None, early_stopping_rounds=None,\n","              enable_categorical=False, eval_metric=None, feature_types=None,\n","              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n","              interaction_constraints=None, learning_rate=None, max_bin=None,\n","              max_cat_threshold=None, max_cat_to_onehot=None,\n","              max_delta_step=None, max_depth=None, max_leaves=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=None, nthread=4, num_parallel_tree=None,\n","              predictor=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"]},"metadata":{},"execution_count":75}]},{"cell_type":"code","source":["y_pred_train = grid_search.best_estimator_.predict(df_x_train)\n","\n","train_score = f1_score(y_train, y_pred_train, average=\"macro\")"],"metadata":{"id":"nIid32d4IGBW","executionInfo":{"status":"ok","timestamp":1688176557487,"user_tz":360,"elapsed":5,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}}},"execution_count":76,"outputs":[]},{"cell_type":"code","source":["print(\"Tuned Hyperparameters :\", grid_search.best_params_)\n","print(f\"F1-score Train: {train_score}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZdJFfz51foi_","executionInfo":{"status":"ok","timestamp":1688176557487,"user_tz":360,"elapsed":4,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}},"outputId":"08b33c59-9fb5-487b-c90c-926055ad73b3"},"execution_count":77,"outputs":[{"output_type":"stream","name":"stdout","text":["Tuned Hyperparameters : {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 60}\n","F1-score Train: 0.9025341130604289\n"]}]},{"cell_type":"markdown","source":["### Validación"],"metadata":{"id":"-1bc1EOixAN0"}},{"cell_type":"code","source":["y_pred = grid_search.best_estimator_.predict(df_x_test)"],"metadata":{"id":"kg6Nh0vgnezA","executionInfo":{"status":"ok","timestamp":1688176557919,"user_tz":360,"elapsed":435,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}}},"execution_count":78,"outputs":[]},{"cell_type":"code","source":["confusion_matrix(y_pred, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e7TJ1Jn5xN9m","executionInfo":{"status":"ok","timestamp":1688176557920,"user_tz":360,"elapsed":12,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}},"outputId":"4295fe54-dd27-461b-c0b3-399c8c829310"},"execution_count":79,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 0,  0],\n","       [ 4, 64]])"]},"metadata":{},"execution_count":79}]},{"cell_type":"code","source":["print(classification_report(y_pred, y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yK7hSNbzxWI4","executionInfo":{"status":"ok","timestamp":1688176557920,"user_tz":360,"elapsed":11,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}},"outputId":"f2400726-56ee-4742-b0df-85b005fb755f"},"execution_count":80,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","         0.0       0.00      0.00      0.00         0\n","         1.0       1.00      0.94      0.97        68\n","\n","    accuracy                           0.94        68\n","   macro avg       0.50      0.47      0.48        68\n","weighted avg       1.00      0.94      0.97        68\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","source":["test_score = f1_score(y_test, y_pred, average=\"macro\")"],"metadata":{"id":"r3U-UyOExdaZ","executionInfo":{"status":"ok","timestamp":1688176557920,"user_tz":360,"elapsed":8,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}}},"execution_count":81,"outputs":[]},{"cell_type":"code","source":["print(f\"Train score: {train_score} \\nTest score: {test_score}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TckTTOJ1xexx","executionInfo":{"status":"ok","timestamp":1688176557921,"user_tz":360,"elapsed":8,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}},"outputId":"c3aad049-2f6e-4138-9489-6660cca68c26"},"execution_count":82,"outputs":[{"output_type":"stream","name":"stdout","text":["Train score: 0.9025341130604289 \n","Test score: 0.48484848484848486\n"]}]},{"cell_type":"markdown","source":["Al revisar los scores, es posible decir que también se dio un overfitting, o sobreentreamiento de los modelos. Se ajusto muy bien en los datos de train, pero no tuvo un buen desempeño en los datos de test."],"metadata":{"id":"-n0DXlarLO-_"}},{"cell_type":"code","source":["# Guardando el modelo\n","XGB_ESTIMATOR_PATH = \"/content/xgb_estimator\"\n","save_to_pickle(logreg_gs.best_estimator_, LR_ESTIMATOR_PATH)"],"metadata":{"id":"-eFeL8oZC17o","executionInfo":{"status":"ok","timestamp":1688176557921,"user_tz":360,"elapsed":6,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}}},"execution_count":83,"outputs":[]},{"cell_type":"markdown","source":["Comparando el score para ambos modelos (Logistic Regression y XGB), el que tuvo mejor desempeño fue **Logistic Regession**, debido a tuvo un mejor score en los datos de test."],"metadata":{"id":"cDpE9KN0DH1f"}},{"cell_type":"markdown","source":["# Function to process and predict new data"],"metadata":{"id":"PLBuRsyU-slC"}},{"cell_type":"code","source":["#!/usr/bin/python3\n","#-*- coding: utf-8 -*-\n","\n","\"\"\"Programa que realiza determinar si una reseña es positiv o negativa para\"\"\"\n","\n","__author__ = \"Cuauhtémoc\"\n","__version__ = \"1.0\"\n","__status__ = \"Development\"\n","\n","import pandas as pd\n","\n","import emoji\n","import nltk\n","import matplotlib.pyplot as plt\n","from wordcloud import WordCloud\n","from nltk.stem import WordNetLemmatizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import pickle\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import GridSearchCV\n","import numpy as np\n","\n","# Descargando librería stopwords\n","nltk.download('stopwords')\n","# Descargando librería para lematización\n","nltk.download('wordnet')\n","\n","# Obteniendo stopwords para idioma inglés\n","STOPWORDS = nltk.corpus.stopwords.words('english')\n","VECTORIZER_PATH = '/content/vectorizer'\n","LR_ESTIMATOR_PATH = \"/content/lr_estimator\"\n","XGB_ESTIMATOR_PATH = \"/content/xgb_estimator\"\n","BEST_MODEL_PATH = LR_ESTIMATOR_PATH\n","\n","\n","LEMMATIZER = WordNetLemmatizer()\n","\n","def remove_stopwords(text: str) -> str:\n","  text_processed = \" \".join(word for word in text.split(\" \") if word not in STOPWORDS)\n","  return text_processed\n","\n","\n","def remove_punctuation(text: str) -> str:\n","  remove_chars_list = [\"?\", \",\", \".\", \";\", \":\",  \"!\",'\"']\n","\n","  for char in remove_chars_list:\n","    text = text.replace(char, \" \")\n","\n","  return text\n","\n","\n","def lemmatisation(text: str) -> str:\n","  return \" \".join(LEMMATIZER.lemmatize(word) for word in text.split(\" \"))\n","\n","\n","def remove_emoji(text: str) -> str:\n","  return emoji.replace_emoji(text, '')\n","\n","\n","def remove_short_words(text: str) -> str:\n","  return \" \".join(word for word in text.split(\" \") if len(word) > 2)\n","\n","\n","def encode_categories(df: pd.DataFrame) -> pd.DataFrame:\n","  df.loc[df[\"sentiment\"] == \"good\", \"target\"] = 1\n","  df.loc[df[\"sentiment\"] == \"bad\", \"target\"] = 0\n","\n","  return df\n","\n","\n","def process_text(df: pd.DataFrame) -> pd.DataFrame:\n","  # [0] Combinando titulo y la descripción\n","  df[\"feature\"] = df[\"reviewTitle\"]  + \" \" + df[\"reviewDescription\"]\n","  # [1] Eliminando signos de puntuación\n","  df[\"feature\"] = df['feature'].apply(remove_punctuation)\n","  # [2] Convirtiendo a minúscula\n","  df[\"feature\"] = df['feature'].str.lower()\n","  # [3] Eliminando las palabras más comunes\n","  df[\"feature\"] = df['feature'].apply(remove_stopwords)\n","  # [4] Lematización\n","  df[\"feature\"] = df['feature'].apply(lemmatisation)\n","  # [5] Removiendo emojis\n","  df[\"feature\"] = df['feature'].apply(remove_emoji)\n","  # [6] Filtrando palabras muy cortas\n","  df[\"feature\"] = df['feature'].apply(remove_short_words)\n","  # [7] Eliminando espacios en blanco al inicio y final del texto\n","  df[\"feature\"] = df['feature'].str.strip()\n","\n","  return df\n","\n","\n","def vectorize_features(df: pd.DataFrame, ) -> pd.DataFrame:\n","  file = open(VECTORIZER_PATH, 'rb')\n","  vectorizer = pickle.load(file)\n","  file.close()\n","\n","  train_vec = vectorizer.transform(df)\n","  df_vectorized = pd.DataFrame.sparse.from_spmatrix(train_vec)\n","\n","  return df_vectorized\n","\n","# Flujo para cargar el modelo y realizar predicción\n","import sklearn\n","def load_model():\n","  file = open(BEST_MODEL_PATH, 'rb')\n","  estimator = pickle.load(file)\n","  file.close()\n","\n","  return estimator\n","\n","\n","def main(df):\n","\n","  # [1] Preprocseamiento (limpieza del texto)\n","  df_processed = process_text(df)\n","  # [2] Vectorización\n","  features = vectorize_features(df_processed[\"feature\"])\n","  # [3] Cargando el modelo\n","  estimator = load_model()\n","  # [4] Realizando la predicción\n","  y = estimator.predict(features)[0]\n","\n","  sentiment = \"good\"\n","  if y == 0:\n","    sentiment = \"bad\"\n","\n","  return sentiment"],"metadata":{"id":"3qzLNEEqAIoA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1688176842503,"user_tz":360,"elapsed":202,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}},"outputId":"44d556c3-33eb-4127-fa0c-d2d31f3b6982"},"execution_count":86,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}]},{"cell_type":"markdown","source":["# Simulación de la llegada de nuevos datos"],"metadata":{"id":"HZjdOe3u_tjT"}},{"cell_type":"code","source":["df_raw = pd.read_csv(\"/content/flipkart_review_data_2022_02.csv\")\n","df_raw = df_raw.drop(columns=\"Unnamed: 0\")\n","\n","df_raw[\"sentiment\"] = df_raw[\"reviewTitle\"].apply(relabel_target)"],"metadata":{"id":"y26YGy0F_Jne","executionInfo":{"status":"ok","timestamp":1688176848755,"user_tz":360,"elapsed":3,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}}},"execution_count":88,"outputs":[]},{"cell_type":"code","source":["df_test = pd.concat([df_raw[df_raw[\"sentiment\"] == \"bad\"].sample(5),\n","                    df_raw[df_raw[\"sentiment\"] == \"good\"].sample(5)])"],"metadata":{"id":"KvgFBoYL__-v","executionInfo":{"status":"ok","timestamp":1688176852176,"user_tz":360,"elapsed":154,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}}},"execution_count":89,"outputs":[]},{"cell_type":"code","source":["df_test.groupby(\"sentiment\")[\"sentiment\"].count()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KLqSNuq1LHcf","executionInfo":{"status":"ok","timestamp":1688176853257,"user_tz":360,"elapsed":198,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}},"outputId":"8d92b2aa-b6c7-433f-aaf3-1c31c894e580"},"execution_count":90,"outputs":[{"output_type":"execute_result","data":{"text/plain":["sentiment\n","bad     5\n","good    5\n","Name: sentiment, dtype: int64"]},"metadata":{},"execution_count":90}]},{"cell_type":"code","source":["import time\n","\n","for index, row in df_test.iterrows():\n","  sentiment = main(pd.DataFrame(row).T)\n","\n","  print(f\"Label: {row['reviewTitle']}\", f\"-> Prediction: {sentiment}\")\n","\n","  time.sleep(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yASw1KQU_yJB","executionInfo":{"status":"ok","timestamp":1688176865551,"user_tz":360,"elapsed":11207,"user":{"displayName":"Temo BE","userId":"10864692948883098013"}},"outputId":"3d3b4732-c724-41b0-8713-db0ea84b9b04"},"execution_count":91,"outputs":[{"output_type":"stream","name":"stdout","text":["Label: Worst experience ever! -> Prediction: good\n","Label: Could be way better -> Prediction: bad\n","Label: Not recommended at all -> Prediction: bad\n","Label: Not recommended at all -> Prediction: good\n","Label: Very poor -> Prediction: bad\n","Label: Best in the market! -> Prediction: good\n","Label: Really Nice -> Prediction: good\n","Label: Really Nice -> Prediction: good\n","Label: Good quality product -> Prediction: good\n","Label: Terrific purchase -> Prediction: good\n"]}]},{"cell_type":"markdown","source":["# Explanation of approach and decisions\n","\n","El primer paso fue realizar fue realizar un filtrado de los comentarios, para obtener los comentarios de mejor calidad. Esto al eliminar el 1% de los comentarios con más dislikes.\n","\n","El siguiente paso fue categorizar y crear una etiqueta para nuestros datos y puedan alimentar a los modelos, para ello utilicé como base, los titulos de los reviews.\n","\n","Generé dos etiquetas: \"good\" y \"bad\". Al revisar la distribución de los datos, noté que la etiqueta \"good\" caracteriza a la mayoría de comentarios, por lo tanto los datos se encuentran desbalanceados.\n","\n","El siguiente paso fue la obtención de los datos de train y test, normalmente se usa un 70% para los datos de entrenamiento y un 30% para los datos de test. Pero al contar con muy pocos registros, decidí usar 80-20, para tener una mayor cantidad de dastos para el entrenamiento.\n","\n","Para tratar datos no balanceados, se puede:\n","- Realizar un sub-muestreo de la data que tiene mayor cantidad de datos\n","- Realizar un sobre-muestreo de la etiqueta con menor cantidad de datos\n","- Usar stratify cross validation\n","- Ensamblado de diferentes modelos, realizando un submuestreo de la categoría con mayor cantidad de datos y siempre usando la categoría con menos datos\n","\n","Por el tiempo disponible opté por usar stratify cross validation que se integra dentro de la función GridSearch.\n","\n","Tanto la columna tilte como reviewDescription fueron concatenadas, para ser utilizadas como \"feature\" para la construcción del modelo, el preprocesamiento incluyo:\n","\n","- Eliminar signos de puntuación\n","- Convertir a minúsculas\n","- Remover palabras más comunes (stopwords)\n","- Eliminación de emojis\n","- Lematización: llevar a la raiz\n","- Remover palabras menores a 2 letras\n","- Vectorizar la información\n","\n","Ya que es un problema de clasificación, use dos modelos de clasificación supervisada, Logistic Regression y XGB. Use diferentes hiperparametros que generaron diversos submodelos y poder evaluar una mayor cantidad de estos, mediante f1 score.\n","\n","Una buen métrica para evaluar el modelo es f1-score, ya que los datos se encuentran desbalaceados\n","\n","En ambos modelos tuvieron un buen desempeño con los datos de entrenamiento, pero no muy bien con los datos de train, por lo que se dio un overfitting (sobreentramiento).\n","\n","El modelo Logistic Regression tiene un desempeño acetable.\n","\n","En cuanto a oportunidades de mejora están:\n","- Utilizar los emojis dentro del modelo\n","- Tener una mayor cantidad de datos\n","- Evaluar la obtención de las etiquetas \"good\" y \"bad\"\n","- Probar técnias de reducción de dimensionalidad (PCA)\n","- Probar con otros parámetros al vectorizar con la función TfidfVectorizer\n","- Evaluar más algoritmos e hiperparametros: svm, knn, random forest, naives bayes\n","- Mejorar el score de manera general, y tener cuidado con el overfitting.\n"],"metadata":{"id":"ReHLobuDPppq"}}]}